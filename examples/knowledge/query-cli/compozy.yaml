name: knowledge-query-cli
version: 0.1.0
description: Minimal setup for experimenting with the compozy knowledge query CLI

models:
  - provider: groq
    model: openai/gpt-oss-120b
    api_key: "{{ .env.GROQ_API_KEY }}"
    default: true
    params:
      temperature: 0.3

embedders:
  - id: openai_default
    provider: openai
    model: text-embedding-3-small
    api_key: "{{ .env.OPENAI_API_KEY }}"
    config:
      dimension: 1536
      batch_size: 64

vector_dbs:
  - id: in_memory_faststart
    type: memory
    config:
      dimension: 1536

knowledge_bases:
  - id: runbook_kb
    ingest: on_start
    embedder: openai_default
    vector_db: in_memory_faststart
    sources:
      - type: markdown_glob
        path: "docs/**/*.md"
    chunking:
      strategy: recursive_text_splitter
      size: 512
      overlap: 64
    retrieval:
      top_k: 5
      min_score: 0.15
      max_tokens: 1200
      filters:
        tags: runbook
    metadata:
      tags:
        - runbook

runtime:
  type: bun
  entrypoint: "./entrypoint.ts"
  permissions:
    - --allow-read
    - --allow-net

workflows:
  - source: ./workflows/qa.yaml

autoload:
  enabled: true
  strict: true
  include:
    - "agents/*.yaml"
    - "workflows/*.yaml"
    - "docs/**/*.md"
  exclude:
    - "**/*.tmp"
    - "**/*~"
