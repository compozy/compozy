# Compozy Dynamic MCP Proxy – Product Requirements Document (PRD)

## 1. Purpose & Vision
Compozy workflows often need to call multiple Model Context Protocol (MCP) servers/tools.
Today we depend on `mcp-proxy` which boots once from a static `config.json`.
We need a **dynamic proxy** that can be started once and then have MCP servers **added, removed, or updated at runtime** as Compozy projects/workflows are (re)loaded.
This PRD defines the requirements for that new service (codename _compozy-mcp-proxy_).

### Codebase Layout Decision
To ease migration we will vendor the original upstream reference code **as-is** under
`pkg/mcp-proxy/old/` (read-only, not compiled).  All new dynamic proxy source code
will live in `pkg/mcp-proxy/`.

## 2. Goals
- ☑️ Provide a single HTTP/SSE endpoint through which Compozy workflows can access any registered MCP server/tool.
- ☑️ Expose a management **REST API** to **Add / Remove / Update / List** MCP client definitions _without restarting the process_.
- ☑️ Persist the active configuration so that the proxy can **restore state** across restarts.
- ☑️ Stay 100 % compatible with MCP protocol v1 (latest) so existing tools keep working.
- ☑️ Offer transparent pass-through for `ListTools`, `CallTool`, `Ping`, resources, prompts, etc.

## 3. Non-Goals
- ✗ Building a UI dashboard (CLI & API are enough for v1).
- ✗ Implementing new transports beyond those already supported by `mcp-go` (stdio, sse, streamable-http).
- ✗ Advanced auth (JWT/OAuth) – simple token header is sufficient.

## 4. Functional Requirements
1. **Runtime MCP Management API**
   - `POST   /admin/mcps`        → Add a new MCP client definition
   - `PUT    /admin/mcps/{name}` → Update existing definition (hot-reload)
   - `DELETE /admin/mcps/{name}` → Remove MCP & disconnect safely
   - `GET    /admin/mcps`        → List all configured MCPs & status (connected, error…)
2. **Supported MCP Client Types**
   - `stdio`, `sse`, `streamable-http` (parity with current proxy).
3. **Hot Reload Logic**
   - New/updated clients are connected **asynchronously**; failures are surfaced via a status field.
   - Removed clients are **gracefully shutdown**: stop ping, close streams, detach routes.
4. **Persistence Layer**
   - Persist MCP definitions in the cluster-wide **Redis** instance already used by the Compozy engine.
   - Uses a dedicated key-space prefix `mcp_proxy:*` to avoid collisions.
   - Relies on Redis AOF for durability; HA handled by Redis Sentinel/Cluster.
5. **Auth & RBAC**
   - Proxy endpoints: optional global `Authorization: <token>` (env var driven).
   - Management API: separate token list + IP allow-list.
6. **Health Endpoint**
   - `/healthz` returns 200 if main loop alive.
7. **Logging**
   - Use the shared `pkg/logger` package for structured and leveled logs with per-client prefix.
8. **Configuration File (Optional)**
   - The service can still start with a JSON config identical to today for easy migration.
   - _If provided_, those MCPs are loaded at boot _in addition to_ persisted ones.
9. **Graceful Shutdown**
   - SIGINT/SIGTERM → Close all MCP clients with timeout, flush DB.

## 5. Non-Functional Requirements
- **Performance:** Add/remove MCP in < 500 ms, proxy throughput ≥ 100 req/s.
- **Reliability:** Auto-reconnect dropped SSE/HTTP clients with back-off.
- **Security:** No secrets printed in logs.
- **Resource Usage:** Memory ≤ 128 MiB with 20 active MCPs.
- **Compatibility:** Go 1.23+, Linux & macOS containers.
- **Persistence backend is **Redis** (AOF enabled).  Eliminates multi-instance state divergence and aligns with existing infrastructure.**

## 6. Proposed API Schemas (REST – JSON)
### 6.1 MCP Definition
```jsonc
{
  "name": "github",
  "transportType": "stdio" | "sse" | "streamable-http",
  "command": "npx",
  "args": ["-y", "@modelcontextprotocol/server-github"],
  "env": {"GITHUB_PERSONAL_ACCESS_TOKEN": "..."},
  "url": "https://mcp.example.com/sse",
  "headers": {"Authorization": "token"},
  "timeout": "30s",
  "options": {
    "panicIfInvalid": false,
    "logEnabled": true,
    "authTokens": ["DefaultToken"],
    "toolFilter": {"mode": "block", "list": ["create_or_update_file"]}
  }
}
```

### 6.2 Management Endpoints
| Method | Path | Body | Response |
|--------|------|------|----------|
| POST   | /admin/mcps        | MCP Definition | 201 Created / 4xx |
| PUT    | /admin/mcps/{name} | MCP Definition | 200 OK / 4xx |
| DELETE | /admin/mcps/{name} | —              | 204 No Content |
| GET    | /admin/mcps        | —              | `[MCP Definition + status]` |

## 7. User Stories / Acceptance Criteria
1. **As a Compozy workflow developer** I can call tools hosted on any MCP registered through the proxy without changing workflow code.
2. **As an operator** I can add a new MCP via `curl -XPOST` and within seconds see its tools available under `/newname/sse`.
3. **As an operator** I can update the headers/token of a running MCP via `PUT` and the connection is refreshed.
4. **As an operator** I receive `409 Conflict` if I try to add another MCP with the same name.
5. **As an operator** I can delete an MCP and further calls to its tools return `404`.
6. **As a DevOps engineer** I can query `/healthz` to monitor basic liveness.

## 8. Open Questions & Risks
- Should we multiplex multiple tool names that clash between MCP servers?  _Proposed_: keep same semantics as base path segmentation.
- Persistence backend choice – **BadgerDB selected** for its concurrency performance and pure-Go implementation (JSON remains a lightweight fallback).
- Bounding resource usage when hundreds of MCPs registered.

## 9. Milestones & Timeline (T-shirt estimates)
| Phase | Deliverable | Duration |
|-------|-------------|----------|
| M0    | Project scaffold, Dockerfile, baseline proxy copied | 2 d |
| M1    | Management API (add/remove/list) + hot reload | 4 d |
| M2    | Persistence layer & startup restore | 2 d |
| M3    | Health endpoint and basic logging | 1 d |
| M4    | Auth/RBAC & security hardening | 2 d |
| M5    | Documentation & examples | 1 d |

## 10. Out-of-Scope / Future Work
- Web dashboard UI.
- Automatic scaling / sharding.
- Multi-tenant RBAC.

## 11. Integration with Compozy Engine
The dynamic proxy must seamlessly plug into the current Compozy execution engine so that **existing workflows continue to work unchanged** while gaining hot-reload capabilities.

### 11.1 Deployment Topology
- The proxy runs as an **independent Go service** (binary or container).
- Default address: `http://localhost:7077` (configurable via `MCP_PROXY_URL` env or *project.yaml*).
- For local development `make run-proxy` spins up the service; in production it is deployed as a side-car/container in the same network.

### 11.2 Configuration Surface
| Location | New Field | Purpose |
|----------|-----------|---------|
| `project.yaml` | `mcp_proxy.url` | Override default proxy base URL for the whole project. |
| `workflow.yaml` | `mcp_proxy.url` | (Optional) Workflow-level override, useful for multi-proxy setups. |
| `engine/mcp/config.go` | *no change* | Individual `workflow.MCPs` definitions remain the same; the engine now forwards them to the proxy instead of creating direct connections. |

### 11.3 Start-up Flow
1. **Server Boot** – `infra/server` checks `MCP_PROXY_URL`.
   - If **reachable**, continue.
   - If not reachable and `MCP_PROXY_AUTO_START=true`, spawn the proxy in-process via `pkg/mcp-proxy/server.Start(ctx, cfg)`.
2. **Workflow Load** – When workflows are parsed the existing `workflow.MCPs` slice is left intact.
3. **Registration** – At the beginning of a workflow run the engine will:
   1. Call `POST /admin/mcps` for each unseen MCP definition.
   2. Ignore `409 Conflict` so that concurrent runs do not fail.
4. **Execution** – `engine/llm/service` replaces `mcp.InitConnections` with lightweight HTTP clients that talk to the proxy endpoint `<baseURL>/{mcpName}/sse` (or `/stream` for streamable-http).

### 11.4 Call Path Changes
```mermaid
sequenceDiagram
    participant Agent
    participant Engine
    participant Proxy
    participant MCP
    Agent->>Engine: ToolCall("mcp-github.create_or_update_file")
    Engine->>Proxy: HTTP SSE /github/sse (tool call)
    Proxy->>MCP: Forwarded call
    MCP-->>Proxy: Stream
    Proxy-->>Engine: Stream
    Engine-->>Agent: Tool result
```

### 11.5 Persistence & Recovery
- The proxy stores its state in Redis under the `mcp_proxy:` namespace. No local disk files are required.
- On engine restart **no action is required**; proxy auto-restores its MCP clients.

### 11.6 Observability & Health
- Proxy logs through shared `pkg/logger`; log level propagates from engine env `LOG_LEVEL`.
- Engine health endpoint `/health` aggregates the proxy's `/healthz` under a `/deps` section.

### 11.7 Migration Plan
| Step | Action |
|------|--------|
| MP-0 | Vendor legacy proxy code under `pkg/mcp-proxy/old/` (done). |
| MP-1 | Implement minimal dynamic proxy shell + health endpoint. |
| MP-2 | Replace `mcp.InitConnections` with proxy registration logic. |
| MP-3 | Add auto-start flag & environment wiring. |
| MP-4 | Remove deprecated static proxy path. |

---
_End of document_
