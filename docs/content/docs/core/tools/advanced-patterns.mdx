---
title: "Advanced Patterns"
description: "Essential advanced patterns for building resilient, production-ready tools with state management, error handling, and performance optimization"
---

Once you've mastered the basics of tool development, these advanced patterns will help you build more sophisticated, resilient tools that can handle complex real-world scenarios.

<Callout type="note">
Start with [TypeScript Development](/docs/core/tools/typescript-development) if you're new to tool development. These patterns build on fundamental concepts and assume familiarity with basic tool creation.
</Callout>

## When to Use Advanced Patterns

Advanced patterns add complexity to your tools. Use them when you need:

- **State persistence** across multiple tool executions
- **Error recovery** in unreliable environments
- **Performance optimization** for high-throughput scenarios
- **Complex data processing** with multiple steps

## Core Patterns

<FeatureCardList>
  <FeatureCard
    icon="Database"
    title="State Management"
    description="Maintain data across tool executions using simple file or memory storage"
  />
  <FeatureCard
    icon="Shield"
    title="Error Recovery"
    description="Graceful handling of failures with retry logic and circuit breakers"
  />
  <FeatureCard
    icon="GitBranch"
    title="Multi-Step Processing"
    description="Break complex operations into manageable, testable steps"
  />
  <FeatureCard
    icon="Zap"
    title="Performance Optimization"
    description="Efficient memory usage, caching, and batch processing"
  />
</FeatureCardList>

## State Management

Simple state management for tools that need to remember data between executions. This is useful for batch processing, counters, or maintaining workflow context.

### Basic File-Based State

The simplest approach uses JSON files to store state between tool executions:

```typescript
// tools/simple-state.ts
export async function run(input: { data: any; state_key: string }) {
  // Load existing state from file (if it exists)
  const stateFile = `./state/${input.state_key}.json`;
  let state = { count: 0, items: [] };
  
  try {
    const data = await Bun.file(stateFile).text();
    state = JSON.parse(data);
  } catch {
    // File doesn't exist yet, use default state
  }

  // Update state with new data
  state.count++;
  state.items.push({
    data: input.data,
    timestamp: new Date().toISOString()
  });

  // Save updated state back to file
  await Bun.$`mkdir -p ./state`;
  await Bun.write(stateFile, JSON.stringify(state, null, 2));

  return {
    processed: input.data,
    state_summary: {
      total_processed: state.count,
      last_item: state.items[state.items.length - 1]
    }
  };
}
```

**What this code does:**
- Loads existing state from a JSON file (or creates default state if file doesn't exist)
- Increments a counter and adds the new item to the state
- Saves the updated state back to the file for the next execution
- Returns both the processed data and a summary of the current state

### Usage in Workflows

```yaml
# workflow.yaml
tasks:
  - id: process-with-state
    type: basic
    $use: tool(local::tools.#(id=="simple-state"))
    with:
      data: "{{ .workflow.input.item }}"
      state_key: "my_processor_{{ .workflow.input.batch_id }}"
    outputs:
      result: "{{ .output.processed }}"
      count: "{{ .output.state_summary.total_processed }}"
```

**How to use this:**
- The `state_key` parameter makes each batch maintain separate state
- State persists across workflow executions
- Use template variables to create unique state keys for different contexts

## Error Handling

Simple error handling patterns for resilient tool execution.

### Basic Retry Logic

Handle temporary failures with simple retry logic:

```typescript
// tools/retry-tool.ts
export async function run(input: { url: string; retries?: number }) {
  const maxRetries = input.retries || 3;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = await fetch(input.url);
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      return {
        success: true,
        data: await response.json(),
        attempts: attempt
      };
    } catch (error) {
      if (attempt === maxRetries) {
        return {
          success: false,
          error: error.message,
          attempts: attempt
        };
      }
      
      // Wait before retrying (exponential backoff)
      await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
    }
  }
}
```

**What this code does:**
- Tries to fetch data from a URL, retrying on failure
- Uses exponential backoff (wait 1s, then 2s, then 3s)
- Returns success/failure status with attempt count
- Prevents infinite loops by limiting retry attempts

### Validation with Fallbacks

Validate input and provide fallback values:

```typescript
// tools/validated-processor.ts
export async function run(input: { data: any; strict?: boolean }) {
  // Validate input data
  if (!input.data) {
    if (input.strict) {
      throw new Error('No data provided');
    }
    return { result: null, warning: 'No data provided, using default' };
  }

  // Process with validation
  try {
    const processed = processData(input.data);
    return { result: processed, status: 'success' };
  } catch (error) {
    if (input.strict) {
      throw error;
    }
    return { 
      result: null, 
      error: error.message, 
      status: 'failed_with_fallback' 
    };
  }
}

function processData(data: any) {
  // Your processing logic here
  return { processed: data, timestamp: new Date().toISOString() };
}
```

**How this works:**
- Validates input before processing
- Provides fallback behavior when `strict` mode is disabled
- Returns detailed status information for debugging
- Allows workflows to continue even when some steps fail

## Performance Optimization

Optimize your tools for production workloads with caching, batch processing, and memory management techniques.

### Batch Processing

Process data in batches to reduce overhead and improve throughput:

```typescript
// tools/batch-processor.ts
export async function run(input: { items: any[]; batch_size?: number }) {
  const batchSize = input.batch_size || 100;
  const results = [];
  
  // Process items in batches
  for (let i = 0; i < input.items.length; i += batchSize) {
    const batch = input.items.slice(i, i + batchSize);
    
    // Process batch in parallel
    const batchResults = await Promise.all(
      batch.map(item => processItem(item))
    );
    
    results.push(...batchResults);
    
    // Log progress for long-running operations
    console.log(`Processed ${i + batch.length} of ${input.items.length} items`);
  }
  
  return {
    processed: results.length,
    results: results,
    batches: Math.ceil(input.items.length / batchSize)
  };
}

async function processItem(item: any) {
  // Your processing logic here
  return { ...item, processed: true };
}
```

**What this code does:**
- Splits large datasets into manageable batches
- Processes items within each batch in parallel
- Provides progress updates for monitoring
- Prevents memory overflow with large datasets

### Memory-Efficient Processing

Handle large files without loading everything into memory:

```typescript
// tools/stream-processor.ts
export async function run(input: { file_path: string; chunk_size?: number }) {
  const chunkSize = input.chunk_size || 1024 * 1024; // 1MB chunks
  const file = Bun.file(input.file_path);
  const stream = file.stream();
  
  let processedBytes = 0;
  let lineBuffer = '';
  
  for await (const chunk of stream) {
    const text = new TextDecoder().decode(chunk);
    const lines = (lineBuffer + text).split('\n');
    
    // Keep last incomplete line for next chunk
    lineBuffer = lines.pop() || '';
    
    // Process complete lines
    for (const line of lines) {
      await processLine(line);
    }
    
    processedBytes += chunk.length;
  }
  
  // Process any remaining data
  if (lineBuffer) {
    await processLine(lineBuffer);
  }
  
  return {
    file: input.file_path,
    processed_bytes: processedBytes,
    status: 'complete'
  };
}

async function processLine(line: string) {
  // Process individual line
  console.log(`Processing: ${line.substring(0, 50)}...`);
}
```

**How this works:**
- Reads files in chunks instead of loading entire file
- Processes data as it streams, reducing memory usage
- Handles text files line by line
- Suitable for processing large log files or datasets

### Simple Caching

Cache expensive operations to improve performance:

```typescript
// tools/cached-api.ts
const cache = new Map<string, { data: any; timestamp: number }>();
const CACHE_TTL = 5 * 60 * 1000; // 5 minutes

export async function run(input: { url: string; cache?: boolean }) {
  const useCache = input.cache !== false;
  const cacheKey = input.url;
  
  // Check cache first
  if (useCache) {
    const cached = cache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
      return {
        data: cached.data,
        cached: true,
        cache_age: Date.now() - cached.timestamp
      };
    }
  }
  
  // Fetch fresh data
  const response = await fetch(input.url);
  const data = await response.json();
  
  // Update cache
  if (useCache) {
    cache.set(cacheKey, { data, timestamp: Date.now() });
  }
  
  return {
    data: data,
    cached: false,
    cache_age: 0
  };
}
```

**What this does:**
- Caches API responses for 5 minutes
- Reduces API calls and improves response time
- Provides cache status in response
- Simple TTL-based cache invalidation

## Multi-Step Processing

Break complex operations into manageable steps for better testing and debugging.

### Pipeline Pattern

Create a processing pipeline with distinct stages:

```typescript
// tools/data-pipeline.ts
interface PipelineStage {
  name: string;
  process: (data: any) => Promise<any>;
  skipOn?: (data: any) => boolean;
}

export async function run(input: { data: any; stages?: string[] }) {
  const allStages: PipelineStage[] = [
    {
      name: 'validate',
      process: async (data) => {
        if (!data || typeof data !== 'object') {
          throw new Error('Invalid data format');
        }
        return data;
      }
    },
    {
      name: 'enrich',
      process: async (data) => ({
        ...data,
        enriched_at: new Date().toISOString(),
        metadata: { source: 'pipeline' }
      })
    },
    {
      name: 'transform',
      process: async (data) => {
        // Transform data structure
        return {
          id: data.id || generateId(),
          content: data,
          version: '2.0'
        };
      }
    },
    {
      name: 'store',
      process: async (data) => {
        // Save to storage (mocked here)
        console.log('Storing data:', data.id);
        return { ...data, stored: true };
      },
      skipOn: (data) => data.skipStorage === true
    }
  ];
  
  // Filter stages if specific ones requested
  const stages = input.stages 
    ? allStages.filter(s => input.stages.includes(s.name))
    : allStages;
  
  let result = input.data;
  const stageResults = [];
  
  for (const stage of stages) {
    try {
      if (stage.skipOn && stage.skipOn(result)) {
        stageResults.push({ 
          stage: stage.name, 
          status: 'skipped' 
        });
        continue;
      }
      
      result = await stage.process(result);
      stageResults.push({ 
        stage: stage.name, 
        status: 'completed' 
      });
    } catch (error) {
      stageResults.push({ 
        stage: stage.name, 
        status: 'failed', 
        error: error.message 
      });
      throw error;
    }
  }
  
  return {
    result: result,
    stages_executed: stageResults,
    pipeline_status: 'completed'
  };
}

function generateId() {
  return `id_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}
```

**What this pattern provides:**
- Clear separation of processing stages
- Easy to test individual stages
- Skip stages based on conditions
- Detailed execution tracking
- Flexible stage selection

### Resilient Service Integration

Simple resilience patterns for reliable external service integration:

```typescript
// tools/resilient-service.ts
export async function run(input: { url: string; fallback_data?: any }) {
  try {
    // Try primary service
    const response = await fetch(input.url, {
      signal: AbortSignal.timeout(10000), // 10 second timeout
    });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}`);
    }
    
    return {
      data: await response.json(),
      source: 'primary',
      status: 'success'
    };
  } catch (error) {
    // Log error for monitoring
    console.error('Primary service failed:', error.message);
    
    // Return fallback data if available
    if (input.fallback_data) {
      return {
        data: input.fallback_data,
        source: 'fallback',
        status: 'degraded',
        error: error.message
      };
    }
    
    // Signal workflow to handle failure
    return {
      data: null,
      source: 'none',
      status: 'failed',
      error: error.message
    };
  }
}
```

**How this pattern works:**
- Simple primary/fallback pattern with timeouts
- Clear error signaling for workflow handling
- Graceful degradation when possible
- Easy to understand and maintain

## Best Practices

<List>
  <ListItem>
    **Keep It Simple**: Start with basic patterns and add complexity only when needed
  </ListItem>
  <ListItem>
    **Test Thoroughly**: Advanced patterns need comprehensive testing, especially error paths
  </ListItem>
  <ListItem>
    **Monitor Performance**: Track execution times and resource usage in production
  </ListItem>
  <ListItem>
    **Document Behavior**: Complex patterns need clear documentation for other developers
  </ListItem>
  <ListItem>
    **Handle Cleanup**: Always clean up resources (files, connections) even on errors
  </ListItem>
</List>

## Related Documentation

<ReferenceCardList>
  <ReferenceCard
    title="TypeScript Development"
    href="/docs/core/tools/typescript-development"
    description="Foundation concepts for building tools with TypeScript"
  />
  <ReferenceCard
    title="Testing & Debugging"
    href="/docs/core/tools/testing-debugging"
    description="Test your advanced patterns with comprehensive debugging tools"
  />
  <ReferenceCard
    title="Performance & Security"
    href="/docs/core/tools/performance-security"
    description="Optimize performance and secure your tool implementations"
  />
  <ReferenceCard
    title="External Integrations"
    href="/docs/core/tools/external-integrations"
    description="Connect to external APIs and services with MCP protocol"
  />
</ReferenceCardList>