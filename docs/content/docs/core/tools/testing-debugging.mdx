---
title: "Testing & Debugging"
description: "Practical guide to testing and debugging Compozy tools with unit tests, integration tests, and debugging strategies"
---

This guide covers practical testing and debugging strategies for Compozy tools, focusing on unit testing, integration testing, and effective debugging techniques for the Bun runtime environment.

<Callout type="info">
Effective testing is crucial for reliable tool development. This guide provides practical approaches using standard testing frameworks adapted for Compozy's Bun runtime environment.
</Callout>

## CLI Testing Commands

### Using Compozy CLI for Testing

Before diving into unit tests, use Compozy CLI commands for end-to-end testing:

```bash
# Initialize new project for testing
compozy init my-test-project

# Start development server with file watching for automatic restarts
compozy dev --watch

# Run configuration diagnostics to verify setup
compozy config diagnostics --verbose

# Show current configuration
compozy config show

# Validate configuration before testing
compozy config validate

# Test workflow execution
compozy workflow list
compozy workflow get [workflow-id]
compozy workflow execute [workflow-id] --input '{"test": true}'

# Test authentication and user management
compozy auth generate --name "Test Key"
compozy auth list
compozy auth create-user --email "test@example.com" --name "Test User"
compozy auth list-users
compozy auth update-user [user-id] --role admin
compozy auth delete-user [user-id]

# Test MCP proxy service
compozy mcp-proxy --port 8081

# Start production server for testing
compozy start
```

## Testing Strategy

### Testing Approach

The testing approach for Compozy tools focuses on:

1. **CLI Integration Tests**: Use Compozy CLI commands for end-to-end testing
2. **Unit Tests**: Test individual tool functions with mocked dependencies
3. **Integration Tests**: Test tools with real external APIs and services
4. **Schema Validation**: Ensure inputs and outputs match defined schemas
5. **Error Handling**: Verify tools handle errors gracefully

<Callout type="note">
Focus on testing the business logic of your tools. The Bun runtime environment handles timeout management, security, and process isolation automatically.
</Callout>

## Setting Up Tests

### Project Structure

```
project/
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ data-processor.ts
‚îÇ   ‚îú‚îÄ‚îÄ data-processor.yaml
‚îÇ   ‚îú‚îÄ‚îÄ data-processor.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ api-client.test.ts
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ vitest.config.ts
```

### Test Configuration

```json
// package.json
{
  "name": "compozy-tools",
  "type": "module",
  "scripts": {
    "test": "vitest",
    "test:watch": "vitest --watch",
    "test:coverage": "vitest --coverage"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "vitest": "^1.0.0",
    "@vitest/coverage-v8": "^1.0.0"
  }
}
```

```typescript
// vitest.config.ts
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    coverage: {
      reporter: ['text', 'json', 'html'],
      exclude: ['node_modules/', 'test/']
    }
  }
});
```

## Unit Testing

### Basic Tool Testing

Test your tool's core functionality:

```typescript
// data-processor.test.ts
import { describe, it, expect, vi } from 'vitest';
import { run } from './data-processor';

describe('Data Processor Tool', () => {
  it('should process data successfully', async () => {
    const input = {
      data: [
        { id: 1, name: 'Alice' },
        { id: 2, name: 'Bob' }
      ],
      format: 'csv'
    };

    const result = await run(input);

    expect(result.success).toBe(true);
    expect(result.data).toContain('id,name');
    expect(result.data).toContain('1,Alice');
    expect(result.data).toContain('2,Bob');
    expect(result.metadata.processed_count).toBe(2);
  });

  it('should handle empty data', async () => {
    const input = {
      data: [],
      format: 'json'
    };

    await expect(run(input)).rejects.toThrow('Data array cannot be empty');
  });

  it('should validate format parameter', async () => {
    const input = {
      data: [{ test: 'value' }],
      format: 'invalid' as any
    };

    await expect(run(input)).rejects.toThrow('Format must be one of: json, csv, xml');
  });
});
```

### Testing with Mocked Dependencies

Mock external services for isolated testing:

```typescript
// api-client.test.ts
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { run } from './api-client';

// Mock fetch globally
global.fetch = vi.fn();

describe('API Client Tool', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  it('should make successful API calls', async () => {
    const mockResponse = { success: true, data: 'test' };
    (global.fetch as any).mockResolvedValueOnce({
      ok: true,
      status: 200,
      json: async () => mockResponse
    });

    const input = {
      endpoint: '/api/test',
      method: 'GET'
    };

    const result = await run(input);

    expect(result.status).toBe(200);
    expect(result.data).toEqual(mockResponse);
    expect(global.fetch).toHaveBeenCalledWith(
      expect.stringContaining('/api/test'),
      expect.objectContaining({
        method: 'GET',
        headers: expect.any(Object)
      })
    );
  });

  it('should handle API errors', async () => {
    (global.fetch as any).mockResolvedValueOnce({
      ok: false,
      status: 404,
      statusText: 'Not Found',
      json: async () => ({ error: 'Not found' })
    });

    const input = {
      endpoint: '/api/notfound',
      method: 'GET'
    };

    const result = await run(input);

    expect(result.status).toBe(404);
    expect(result.error).toBe('HTTP 404: Not Found');
  });

  it('should handle network errors', async () => {
    (global.fetch as any).mockRejectedValueOnce(new Error('Network error'));

    const input = {
      endpoint: '/api/test',
      method: 'GET'
    };

    const result = await run(input);

    expect(result.status).toBe(0);
    expect(result.error).toBe('Network error');
  });
});
```

### Testing Error Handling

Ensure your tools handle errors gracefully:

```typescript
// error-handling.test.ts
import { describe, it, expect } from 'vitest';
import { run } from './file-processor';

describe('File Processor Error Handling', () => {
  it('should handle file not found', async () => {
    const input = {
      operation: 'read',
      path: '/nonexistent/file.txt'
    };

    const result = await run(input);

    expect(result.success).toBe(false);
    expect(result.error).toContain('ENOENT');
  });

  it('should handle permission errors', async () => {
    const input = {
      operation: 'write',
      path: '/root/protected.txt',
      content: 'test'
    };

    const result = await run(input);

    expect(result.success).toBe(false);
    expect(result.error).toContain('permission');
  });

  it('should handle timeout gracefully', async () => {
    const input = {
      operation: 'process',
      url: 'https://httpstat.us/200?sleep=60000' // 60 second delay
    };

    const result = await run(input);

    expect(result.success).toBe(false);
    expect(result.error).toContain('timeout');
  });
});
```

## Integration Testing

### Testing with Real APIs

Test your tools against real services:

```typescript
// github-integration.test.ts
import { describe, it, expect, beforeAll } from 'vitest';
import { run } from './github-client';

describe('GitHub Client Integration', () => {
  let token: string;

  beforeAll(() => {
    token = process.env.GITHUB_TOKEN || '';
    if (!token) {
      throw new Error('GITHUB_TOKEN environment variable required for integration tests');
    }
  });

  it('should fetch user repositories', async () => {
    const input = {
      endpoint: '/user/repos',
      method: 'GET'
    };

    // Set up environment
    process.env.GITHUB_TOKEN = token;

    const result = await run(input);

    expect(result.status).toBe(200);
    expect(Array.isArray(result.data)).toBe(true);
    expect(result.data.length).toBeGreaterThan(0);
    expect(result.data[0]).toHaveProperty('name');
    expect(result.data[0]).toHaveProperty('full_name');
  });

  it('should handle rate limiting', async () => {
    const input = {
      endpoint: '/rate_limit',
      method: 'GET'
    };

    process.env.GITHUB_TOKEN = token;

    const result = await run(input);

    expect(result.status).toBe(200);
    expect(result.data).toHaveProperty('rate');
    expect(result.data.rate).toHaveProperty('limit');
    expect(result.data.rate).toHaveProperty('remaining');
  });
});
```

### Testing File Operations

Test file system operations with temporary directories:

```typescript
// file-operations.test.ts
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { run } from './file-handler';
import { mkdtemp, rm } from 'fs/promises';
import { tmpdir } from 'os';
import { join } from 'path';

describe('File Handler Integration', () => {
  let tempDir: string;

  beforeEach(async () => {
    tempDir = await mkdtemp(join(tmpdir(), 'test-'));
  });

  afterEach(async () => {
    await rm(tempDir, { recursive: true, force: true });
  });

  it('should write and read files', async () => {
    const testFile = join(tempDir, 'test.txt');
    const content = 'Hello, Compozy!';

    // Write file
    const writeResult = await run({
      operation: 'write',
      path: testFile,
      content: content
    });

    expect(writeResult.success).toBe(true);

    // Read file
    const readResult = await run({
      operation: 'read',
      path: testFile
    });

    expect(readResult.success).toBe(true);
    expect(readResult.data).toBe(content);
  });

  it('should list directory contents', async () => {
    // Create test files
    await run({ operation: 'write', path: join(tempDir, 'file1.txt'), content: 'test1' });
    await run({ operation: 'write', path: join(tempDir, 'file2.txt'), content: 'test2' });

    const listResult = await run({
      operation: 'list',
      path: tempDir
    });

    expect(listResult.success).toBe(true);
    expect(listResult.data).toHaveLength(2);
    expect(listResult.data).toContain('file1.txt');
    expect(listResult.data).toContain('file2.txt');
  });
});
```

## Schema Validation Testing

### Testing Input Validation

Verify your tools validate inputs correctly:

```typescript
// schema-validation.test.ts
import { describe, it, expect } from 'vitest';
import { validateInput } from './data-processor';

describe('Data Processor Schema Validation', () => {
  it('should accept valid input', () => {
    const validInput = {
      data: [{ id: 1, name: 'test' }],
      format: 'json',
      options: {
        pretty: true
      }
    };

    const result = validateInput(validInput);
    expect(result.valid).toBe(true);
    expect(result.errors).toBeUndefined();
  });

  it('should reject missing required fields', () => {
    const invalidInput = {
      // missing 'data' field
      format: 'json'
    };

    const result = validateInput(invalidInput);
    expect(result.valid).toBe(false);
    expect(result.errors).toContain('data is required');
  });

  it('should reject invalid data types', () => {
    const invalidInput = {
      data: 'not-an-array', // should be array
      format: 'json'
    };

    const result = validateInput(invalidInput);
    expect(result.valid).toBe(false);
    expect(result.errors).toContain('data must be an array');
  });

  it('should reject invalid enum values', () => {
    const invalidInput = {
      data: [],
      format: 'yaml' // not in enum: ['json', 'csv', 'xml']
    };

    const result = validateInput(invalidInput);
    expect(result.valid).toBe(false);
    expect(result.errors).toContain('format must be one of: json, csv, xml');
  });
});
```

## Debugging Tools

### Debug Logging

Add debug logging to your tools:

```typescript
// debug-helper.ts
export class DebugLogger {
  private enabled: boolean;

  constructor() {
    this.enabled = process.env.DEBUG === 'true';
  }

  log(message: string, data?: any): void {
    if (this.enabled) {
      console.log(`[DEBUG] ${new Date().toISOString()} - ${message}`);
      if (data) {
        console.log(JSON.stringify(data, null, 2));
      }
    }
  }

  error(message: string, error: Error): void {
    if (this.enabled) {
      console.error(`[ERROR] ${new Date().toISOString()} - ${message}`);
      console.error(error.stack || error.message);
    }
  }

  time(label: string): void {
    if (this.enabled) {
      console.time(label);
    }
  }

  timeEnd(label: string): void {
    if (this.enabled) {
      console.timeEnd(label);
    }
  }
}

// Usage in tools
const debug = new DebugLogger();

export async function run(input: ToolInput): Promise<ToolOutput> {
  debug.log('Tool execution started', { input });
  debug.time('execution');

  try {
    const result = await processData(input);
    debug.log('Tool execution completed', { result });
    debug.timeEnd('execution');
    return result;
  } catch (error) {
    debug.error('Tool execution failed', error);
    debug.timeEnd('execution');
    throw error;
  }
}
```

### Memory Usage Monitoring

Monitor memory usage during development:

```typescript
// memory-monitor.ts
export function logMemoryUsage(label: string): void {
  if (process.env.DEBUG_MEMORY === 'true') {
    const usage = process.memoryUsage();
    console.log(`[MEMORY] ${label}:`, {
      heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)}MB`,
      heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)}MB`,
      rss: `${Math.round(usage.rss / 1024 / 1024)}MB`
    });
  }
}

// Usage in tools
export async function run(input: LargeDataInput): Promise<ProcessedOutput> {
  logMemoryUsage('Start');

  const data = await loadData(input.source);
  logMemoryUsage('After loading data');

  const processed = await processInBatches(data);
  logMemoryUsage('After processing');

  return processed;
}
```

### Development Testing Script

Create a development script for manual testing:

```typescript
// dev-test.ts
import { run } from './my-tool';

async function testTool() {
  console.log('üß™ Testing tool with sample data...\n');

  const testCases = [
    {
      name: 'Basic functionality',
      input: { data: ['test1', 'test2'], operation: 'process' }
    },
    {
      name: 'Error handling',
      input: { data: [], operation: 'process' }
    },
    {
      name: 'Large dataset',
      input: { data: Array(1000).fill('test'), operation: 'process' }
    }
  ];

  for (const testCase of testCases) {
    console.log(`üìù Test: ${testCase.name}`);
    console.log('Input:', JSON.stringify(testCase.input, null, 2));

    try {
      const start = Date.now();
      const result = await run(testCase.input);
      const duration = Date.now() - start;

      console.log('‚úÖ Success!');
      console.log('Duration:', `${duration}ms`);
      console.log('Result:', JSON.stringify(result, null, 2));
    } catch (error) {
      console.log('‚ùå Failed!');
      console.log('Error:', error.message);
    }

    console.log('\n' + '='.repeat(50) + '\n');
  }
}

// Run if executed directly
if (import.meta.url === `file://${process.argv[1]}`) {
  testTool().catch(console.error);
}
```

## Testing Best Practices

<List>
  <ListItem>
    **Test Real Scenarios**: Write tests that reflect actual usage patterns
  </ListItem>
  <ListItem>
    **Mock External Dependencies**: Use mocks for APIs and services in unit tests
  </ListItem>
  <ListItem>
    **Test Error Cases**: Ensure your tools handle errors gracefully
  </ListItem>
  <ListItem>
    **Use Environment Variables**: Make tests configurable through environment variables
  </ListItem>
  <ListItem>
    **Keep Tests Fast**: Focus on testing your logic, not the runtime environment
  </ListItem>
  <ListItem>
    **Document Test Requirements**: Clearly document any setup needed for tests
  </ListItem>
</List>

## Common Testing Patterns

### Testing Async Operations

```typescript
describe('Async Operations', () => {
  it('should handle concurrent requests', async () => {
    const inputs = [
      { endpoint: '/api/1' },
      { endpoint: '/api/2' },
      { endpoint: '/api/3' }
    ];

    const promises = inputs.map(input => run(input));
    const results = await Promise.all(promises);

    expect(results).toHaveLength(3);
    results.forEach(result => {
      expect(result.status).toBe(200);
    });
  });

  it('should respect timeouts', async () => {
    const input = {
      endpoint: '/api/slow',
      timeout: 1000 // 1 second
    };

    const start = Date.now();
    const result = await run(input);
    const duration = Date.now() - start;

    expect(result.success).toBe(false);
    expect(result.error).toContain('timeout');
    expect(duration).toBeLessThan(1500); // Should fail quickly
  });
});
```

### Testing with Environment Variables

```typescript
describe('Environment Configuration', () => {
  const originalEnv = process.env;

  beforeEach(() => {
    process.env = { ...originalEnv };
  });

  afterEach(() => {
    process.env = originalEnv;
  });

  it('should use environment variables', async () => {
    process.env.API_BASE_URL = 'https://test.example.com';
    process.env.API_KEY = 'test-key-123';

    const input = { endpoint: '/test' };
    const result = await run(input);

    expect(result).toBeDefined();
    // Verify the correct base URL was used
    expect(fetch).toHaveBeenCalledWith(
      'https://test.example.com/test',
      expect.any(Object)
    );
  });

  it('should handle missing environment variables', async () => {
    delete process.env.API_KEY;

    const input = { endpoint: '/test' };
    const result = await run(input);

    expect(result.success).toBe(false);
    expect(result.error).toContain('API_KEY');
  });
});
```

## Related Documentation

<ReferenceCardList>
  <ReferenceCard
    title="CLI Configuration"
    href="/docs/core/configuration/cli"
    description="Complete CLI command reference and configuration options"
  />
  <ReferenceCard
    title="TypeScript Development"
    href="/docs/core/tools/typescript-development"
    description="Learn TypeScript patterns for building Compozy tools"
  />
  <ReferenceCard
    title="Runtime Environment"
    href="/docs/core/tools/runtime-environment"
    description="Understand the Bun execution environment and security"
  />
  <ReferenceCard
    title="Configuration Schemas"
    href="/docs/core/tools/configuration-schemas"
    description="Define and validate tool input/output schemas"
  />
  <ReferenceCard
    title="Advanced Patterns"
    href="/docs/core/tools/advanced-patterns"
    description="Advanced patterns for tool development"
  />
</ReferenceCardList>