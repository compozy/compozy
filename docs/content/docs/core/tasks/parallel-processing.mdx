---
title: Parallel Processing
description: Execute multiple tasks simultaneously with parallel task patterns in Compozy
---

Parallel tasks enable concurrent execution of multiple operations, significantly improving workflow performance and enabling sophisticated processing patterns. They're essential for scalable workflows that need to process multiple items or perform independent operations simultaneously.

## Related Documentation

### üîó Cross-References
- **[Core Concepts: Tasks](/docs/core/getting-started/core-concepts#2-tasks)** - Tasks in workflow context
- **[Basic Tasks](/docs/core/tasks/basic-tasks)** - Foundation tasks executed in parallel
- **[Collection Tasks](/docs/core/tasks/collection-tasks)** - Array processing with parallel modes
- **[YAML Templates](/docs/core/yaml-templates/overview)** - Dynamic parallel configuration

### ‚öôÔ∏è Task-Related Topics
- **Parallel Processing** ‚Üî **[Aggregate Tasks](/docs/core/tasks/aggregate-tasks)** ‚Üî **[Composite Tasks](/docs/core/tasks/composite-tasks)**
- **Concurrent Execution** ‚Üî **[Flow Control](/docs/core/tasks/flow-control)** ‚Üî **[Error Handling](/docs/core/tasks/basic-tasks#error-handling)**
- **Performance Optimization** ‚Üî **[Advanced Patterns](/docs/core/tasks/advanced-patterns)** ‚Üî **[Resource Management](/docs/core/configuration/performance)**

## Overview

Parallel processing in Compozy provides:

- **Concurrent Execution**: Run multiple tasks simultaneously
- **Flexible Strategies**: Choose between wait-all, race, and best-effort modes
- **Resource Control**: Configure worker limits and timeouts
- **Error Handling**: Sophisticated failure handling across parallel branches
- **Result Aggregation**: Collect and combine results from all parallel tasks

<Callout type="info">
Parallel tasks are ideal for I/O-bound operations, independent data processing, and scenarios where operations can safely run concurrently.
</Callout>

## Task Structure

### Basic Parallel Task

```yaml
id: parallel-processing
type: parallel
strategy: wait_all
max_workers: 4
timeout: 5m

tasks:
  - id: task-1
    type: basic
    $use: agent(local::agents.#(id=="processor"))
    action: process_item
    with:
      item: "{{ .workflow.input.item1 }}"

  - id: task-2
    type: basic
    $use: tool(local::tools.#(id=="analyzer"))
    with:
      data: "{{ .workflow.input.item2 }}"

  - id: task-3
    type: basic
    $use: agent(local::agents.#(id=="validator"))
    action: validate
    with:
      content: "{{ .workflow.input.item3 }}"

on_success:
  next: merge-results
  with:
    results:
      task1: "{{ .tasks.task-1.output }}"
      task2: "{{ .tasks.task-2.output }}"
      task3: "{{ .tasks.task-3.output }}"
```

### Configuration Options

<Tabs items={["Strategies", "Worker Control", "Timeouts", "Error Handling"]}>
<Tab value="Strategies">

Control how parallel tasks coordinate:

```yaml
# Wait for all tasks to complete
id: wait-all-example
type: parallel
strategy: wait_all  # Default strategy
timeout: 10m

tasks:
  - id: process-emails
    type: basic
    $use: agent(local::agents.#(id=="email-processor"))
    action: process_batch
    with:
      emails: "{{ .workflow.input.emails }}"

  - id: process-documents
    type: basic
    $use: tool(local::tools.#(id=="doc-processor"))
    with:
      documents: "{{ .workflow.input.documents }}"

---

# Race mode - first to complete wins
id: race-example
type: parallel
strategy: race
timeout: 30s

tasks:
  - id: primary-service
    type: basic
    $use: tool(local::tools.#(id=="primary-api"))
    with:
      query: "{{ .workflow.input.query }}"

  - id: fallback-service
    type: basic
    $use: tool(local::tools.#(id=="fallback-api"))
    with:
      query: "{{ .workflow.input.query }}"

---

# Best effort - continue despite failures
id: best-effort-example
type: parallel
strategy: best_effort
timeout: 5m

tasks:
  - id: optional-task-1
    type: basic
    $use: tool(local::tools.#(id=="optional-processor"))
    with:
      data: "{{ .workflow.input.data }}"

  - id: optional-task-2
    type: basic
    $use: tool(local::tools.#(id=="backup-processor"))
    with:
      data: "{{ .workflow.input.data }}"
```

</Tab>
<Tab value="Worker Control">

Manage parallel execution resources:

```yaml
id: controlled-parallel
type: parallel
strategy: wait_all

# Resource limits
max_workers: 8        # Maximum concurrent tasks
min_workers: 2        # Minimum workers to maintain
worker_timeout: 30s   # Individual worker timeout

# Queue configuration
queue_size: 100       # Maximum queued tasks
priority_mode: fifo   # Queue processing order

tasks:
  # High-priority tasks
  - id: critical-task
    type: basic
    priority: high
    $use: agent(local::agents.#(id=="critical-processor"))
    action: process_critical
    with:
      data: "{{ .workflow.input.critical_data }}"

  # Normal priority tasks
  - id: normal-task-1
    type: basic
    priority: normal
    $use: tool(local::tools.#(id=="standard-processor"))
    with:
      data: "{{ .workflow.input.data1 }}"

  - id: normal-task-2
    type: basic
    priority: normal
    $use: tool(local::tools.#(id=="standard-processor"))
    with:
      data: "{{ .workflow.input.data2 }}"
```

</Tab>
<Tab value="Timeouts">

Configure timeout behavior:

```yaml
id: timeout-controlled
type: parallel
strategy: wait_all

# Global parallel timeout
timeout: 10m

# Individual task timeouts
task_timeout: 2m

# Heartbeat configuration
heartbeat_interval: 30s

tasks:
  - id: fast-task
    type: basic
    # Override global timeout
    timeout: 30s
    $use: tool(local::tools.#(id=="fast-processor"))
    with:
      data: "{{ .workflow.input.fast_data }}"

  - id: slow-task
    type: basic
    # Longer timeout for slow operations
    timeout: 5m
    $use: tool(local::tools.#(id=="slow-processor"))
    with:
      data: "{{ .workflow.input.slow_data }}"

  - id: standard-task
    type: basic
    # Uses global task_timeout (2m)
    $use: agent(local::agents.#(id=="standard-processor"))
    action: process
    with:
      data: "{{ .workflow.input.standard_data }}"
```

</Tab>
<Tab value="Error Handling">

Handle failures in parallel execution:

```yaml
id: resilient-parallel
type: parallel
strategy: wait_all

# Global error handling
on_error:
  next: handle-parallel-errors
  with:
    failed_tasks: "{{ .task.failed_tasks }}"
    successful_tasks: "{{ .task.successful_tasks }}"

# Retry configuration
retry_policy:
  maximum_attempts: 3
  initial_interval: 1s
  maximum_interval: 30s

tasks:
  - id: resilient-task-1
    type: basic
    $use: tool(local::tools.#(id=="resilient-processor"))
    with:
      data: "{{ .workflow.input.data1 }}"

    # Individual error handling
    on_error:
      next: handle-individual-error
      with:
        task_id: "resilient-task-1"
        error: "{{ .task.error }}"

  - id: resilient-task-2
    type: basic
    $use: agent(local::agents.#(id=="resilient-agent"))
    action: process_safely
    with:
      data: "{{ .workflow.input.data2 }}"

    # Custom retry for this task
    retry_policy:
      maximum_attempts: 5
      initial_interval: 2s
```

</Tab>
</Tabs>

## Execution Strategies

### Wait All Strategy

The default strategy that waits for all tasks to complete:

```yaml
id: data-pipeline
type: parallel
strategy: wait_all
max_workers: 6
timeout: 15m

tasks:
  # Data extraction
  - id: extract-users
    type: basic
    $use: tool(local::tools.#(id=="database-client"))
    with:
      query: "SELECT * FROM users WHERE active = true"
      connection: "{{ .env.DB_CONNECTION }}"

  # Data processing
  - id: process-transactions
    type: basic
    $use: agent(local::agents.#(id=="transaction-processor"))
    action: analyze_transactions
    with:
      date_range: "{{ .workflow.input.date_range }}"

  # Report generation
  - id: generate-metrics
    type: basic
    $use: tool(local::tools.#(id=="metrics-generator"))
    with:
      metric_types: ["revenue", "users", "transactions"]
      period: "{{ .workflow.input.period }}"

# All tasks must complete before proceeding
on_success:
  next: combine-results
  with:
    users: "{{ .tasks.extract-users.output }}"
    transactions: "{{ .tasks.process-transactions.output }}"
    metrics: "{{ .tasks.generate-metrics.output }}"
```

### Race Strategy

First task to complete successfully wins:

```yaml
id: multi-provider-search
type: parallel
strategy: race
timeout: 10s

tasks:
  - id: search-provider-a
    type: basic
    $use: tool(local::tools.#(id=="search-api-a"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_A_KEY }}"

  - id: search-provider-b
    type: basic
    $use: tool(local::tools.#(id=="search-api-b"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_B_KEY }}"

  - id: search-provider-c
    type: basic
    $use: tool(local::tools.#(id=="search-api-c"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_C_KEY }}"

# Uses result from first completing task
on_success:
  next: process-search-results
  with:
    results: "{{ .output }}"
    provider: "{{ .winner_task_id }}"
```

### Best Effort Strategy

Continue despite individual task failures:

```yaml
id: notification-broadcast
type: parallel
strategy: best_effort
timeout: 2m

tasks:
  - id: email-notification
    type: basic
    $use: tool(local::tools.#(id=="email-sender"))
    with:
      recipients: "{{ .workflow.input.email_recipients }}"
      subject: "{{ .workflow.input.subject }}"
      body: "{{ .workflow.input.message }}"

  - id: sms-notification
    type: basic
    $use: tool(local::tools.#(id=="sms-sender"))
    with:
      recipients: "{{ .workflow.input.phone_recipients }}"
      message: "{{ .workflow.input.short_message }}"

  - id: push-notification
    type: basic
    $use: tool(local::tools.#(id=="push-sender"))
    with:
      users: "{{ .workflow.input.app_users }}"
      title: "{{ .workflow.input.title }}"
      body: "{{ .workflow.input.message }}"

  - id: slack-notification
    type: basic
    $use: tool(local::tools.#(id=="slack-sender"))
    with:
      channel: "{{ .workflow.input.slack_channel }}"
      message: "{{ .workflow.input.message }}"

# Proceeds even if some notifications fail
on_success:
  next: log-notification-results
  with:
    successful_channels: "{{ .successful_tasks }}"
    failed_channels: "{{ .failed_tasks }}"
```

## Common Patterns

### Dynamic Task Generation

Create parallel tasks from dynamic input:

```yaml
id: dynamic-parallel
type: parallel
strategy: wait_all
max_workers: 4

tasks: "{{ range .workflow.input.items }}"
  - id: "process-{{ .id }}"
    type: basic
    $use: agent(local::agents.#(id=="item-processor"))
    action: process_item
    with:
      item_data: "{{ .data }}"
"{{ end }}"
```

### Resource Management

Configure resource limits for optimal performance:

```yaml
id: resource-controlled
type: parallel
strategy: wait_all
max_workers: "{{ .env.MAX_WORKERS | default 4 }}"

tasks:
  - id: process-data
    type: basic
    $use: tool(local::tools.#(id=="processor"))
    with:
      data: "{{ .workflow.input.data }}"
```

## CLI Commands

The Compozy CLI provides these commands for managing parallel tasks:

```bash
# List all workflows
compozy workflow list

# Execute a parallel workflow
compozy workflow execute my-parallel-workflow

# Get workflow details  
compozy workflow get my-parallel-workflow
```

<Callout type="info">
**Task Management Commands**: Additional CLI commands for task monitoring and control are planned for future releases.
</Callout>

## Quick Examples

### Multi-Service Integration

```yaml
id: fetch-user-data
type: parallel
strategy: wait_all
max_workers: 3

tasks:
  - id: get-profile
    type: basic
    $use: tool(local::tools.#(id=="user-service"))
    with:
      user_id: "{{ .workflow.input.user_id }}"

  - id: get-preferences  
    type: basic
    $use: tool(local::tools.#(id=="preferences-service"))
    with:
      user_id: "{{ .workflow.input.user_id }}"

  - id: get-history
    type: basic
    $use: tool(local::tools.#(id=="history-service"))  
    with:
      user_id: "{{ .workflow.input.user_id }}"

on_success:
  next: merge-results
```

### Data Processing Pipeline

```yaml
id: process-content
type: parallel
strategy: wait_all

tasks:
  - id: extract-text
    type: basic
    $use: tool(local::tools.#(id=="text-extractor"))
    with:
      content: "{{ .workflow.input.content }}"

  - id: process-images
    type: basic
    $use: tool(local::tools.#(id=="image-processor"))
    with:
      images: "{{ .workflow.input.images }}"

  - id: validate-content
    type: basic
    $use: agent(local::agents.#(id=="content-validator"))
    action: validate
    with:
      content: "{{ .workflow.input.content }}"
```

## Performance Tips

### Worker Configuration

```yaml
# CPU-bound tasks: use CPU core count
max_workers: 4

# I/O-bound tasks: use 2x CPU cores  
max_workers: 8

# Set appropriate timeouts
timeout: 5m
```

### Memory Optimization

```yaml
# Process data efficiently
tasks:
  - id: efficient-task
    type: basic
    $use: tool(local::tools.#(id=="processor"))
    with:
      data: "{{ .workflow.input.data }}"
```

## Best Practices

1. **Choose the Right Strategy**: Use `wait_all` for dependent results, `race` for redundancy, `best_effort` for optional operations
2. **Set Appropriate Timeouts**: Balance responsiveness with operation requirements
3. **Monitor Resource Usage**: Configure workers based on available CPU/memory
4. **Handle Failures Gracefully**: Design for partial failure scenarios
5. **Optimize Task Granularity**: Balance parallel efficiency with overhead

## References

<ReferenceCardList>
  <ReferenceCard
    title="Basic Tasks"
    description="Master the foundation tasks that compose parallel workflows"
    href="/docs/core/tasks/basic-tasks"
    icon="Cog"
  />
  <ReferenceCard
    title="Collection Tasks"
    description="Learn to process arrays with parallel execution patterns"
    href="/docs/core/tasks/collection-tasks"
    icon="Grid"
  />
  <ReferenceCard
    title="Aggregate Tasks"
    description="Combine results from parallel task execution"
    href="/docs/core/tasks/aggregate-tasks"
    icon="BarChart"
  />
  <ReferenceCard
    title="Flow Control"
    description="Implement conditional routing in parallel workflows"
    href="/docs/core/tasks/flow-control"
    icon="GitBranch"
  />
</ReferenceCardList>

Parallel processing enables Compozy workflows to scale efficiently and handle complex, concurrent operations while maintaining reliability and performance control.
