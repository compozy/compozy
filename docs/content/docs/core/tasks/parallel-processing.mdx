---
title: Parallel Processing
description: Execute multiple tasks simultaneously with parallel task patterns in Compozy
---

Parallel tasks enable concurrent execution of multiple operations, significantly improving workflow performance and enabling sophisticated processing patterns. They're essential for scalable workflows that need to process multiple items or perform independent operations simultaneously.

## Overview

Parallel processing in Compozy provides:

- **Concurrent Execution**: Run multiple tasks simultaneously
- **Flexible Strategies**: Choose between wait-all, race, and best-effort modes
- **Resource Control**: Configure worker limits and timeouts
- **Error Handling**: Sophisticated failure handling across parallel branches
- **Result Aggregation**: Collect and combine results from all parallel tasks

<Callout type="info">
Parallel tasks are ideal for I/O-bound operations, independent data processing, and scenarios where operations can safely run concurrently.
</Callout>

## Task Structure

### Basic Parallel Task

```yaml
id: parallel-processing
type: parallel
strategy: wait_all
max_workers: 4
timeout: 5m

tasks:
  - id: task-1
    type: basic
    $use: agent(local::agents.#(id=="processor"))
    action: process_item
    with:
      item: "{{ .workflow.input.item1 }}"

  - id: task-2
    type: basic
    $use: tool(local::tools.#(id=="analyzer"))
    with:
      data: "{{ .workflow.input.item2 }}"

  - id: task-3
    type: basic
    $use: agent(local::agents.#(id=="validator"))
    action: validate
    with:
      content: "{{ .workflow.input.item3 }}"

on_success:
  next: merge-results
  with:
    results:
      task1: "{{ .tasks.task-1.output }}"
      task2: "{{ .tasks.task-2.output }}"
      task3: "{{ .tasks.task-3.output }}"
```

### Configuration Options

<Tabs items={["Strategies", "Worker Control", "Timeouts", "Error Handling"]}>
<Tab value="Strategies">

Control how parallel tasks coordinate:

```yaml
# Wait for all tasks to complete
id: wait-all-example
type: parallel
strategy: wait_all  # Default strategy
timeout: 10m

tasks:
  - id: process-emails
    type: basic
    $use: agent(local::agents.#(id=="email-processor"))
    action: process_batch
    with:
      emails: "{{ .workflow.input.emails }}"

  - id: process-documents
    type: basic
    $use: tool(local::tools.#(id=="doc-processor"))
    with:
      documents: "{{ .workflow.input.documents }}"

---

# Race mode - first to complete wins
id: race-example
type: parallel
strategy: race
timeout: 30s

tasks:
  - id: primary-service
    type: basic
    $use: tool(local::tools.#(id=="primary-api"))
    with:
      query: "{{ .workflow.input.query }}"

  - id: fallback-service
    type: basic
    $use: tool(local::tools.#(id=="fallback-api"))
    with:
      query: "{{ .workflow.input.query }}"

---

# Best effort - continue despite failures
id: best-effort-example
type: parallel
strategy: best_effort
timeout: 5m

tasks:
  - id: optional-task-1
    type: basic
    $use: tool(local::tools.#(id=="optional-processor"))
    with:
      data: "{{ .workflow.input.data }}"

  - id: optional-task-2
    type: basic
    $use: tool(local::tools.#(id=="backup-processor"))
    with:
      data: "{{ .workflow.input.data }}"
```

</Tab>
<Tab value="Worker Control">

Manage parallel execution resources:

```yaml
id: controlled-parallel
type: parallel
strategy: wait_all

# Resource limits
max_workers: 8        # Maximum concurrent tasks
min_workers: 2        # Minimum workers to maintain
worker_timeout: 30s   # Individual worker timeout

# Queue configuration
queue_size: 100       # Maximum queued tasks
priority_mode: fifo   # Queue processing order

tasks:
  # High-priority tasks
  - id: critical-task
    type: basic
    priority: high
    $use: agent(local::agents.#(id=="critical-processor"))
    action: process_critical
    with:
      data: "{{ .workflow.input.critical_data }}"

  # Normal priority tasks
  - id: normal-task-1
    type: basic
    priority: normal
    $use: tool(local::tools.#(id=="standard-processor"))
    with:
      data: "{{ .workflow.input.data1 }}"

  - id: normal-task-2
    type: basic
    priority: normal
    $use: tool(local::tools.#(id=="standard-processor"))
    with:
      data: "{{ .workflow.input.data2 }}"
```

</Tab>
<Tab value="Timeouts">

Configure timeout behavior:

```yaml
id: timeout-controlled
type: parallel
strategy: wait_all

# Global parallel timeout
timeout: 10m

# Individual task timeouts
task_timeout: 2m

# Heartbeat configuration
heartbeat_interval: 30s

tasks:
  - id: fast-task
    type: basic
    # Override global timeout
    timeout: 30s
    $use: tool(local::tools.#(id=="fast-processor"))
    with:
      data: "{{ .workflow.input.fast_data }}"

  - id: slow-task
    type: basic
    # Longer timeout for slow operations
    timeout: 5m
    $use: tool(local::tools.#(id=="slow-processor"))
    with:
      data: "{{ .workflow.input.slow_data }}"

  - id: standard-task
    type: basic
    # Uses global task_timeout (2m)
    $use: agent(local::agents.#(id=="standard-processor"))
    action: process
    with:
      data: "{{ .workflow.input.standard_data }}"
```

</Tab>
<Tab value="Error Handling">

Handle failures in parallel execution:

```yaml
id: resilient-parallel
type: parallel
strategy: wait_all

# Global error handling
on_error:
  next: handle-parallel-errors
  with:
    failed_tasks: "{{ .task.failed_tasks }}"
    successful_tasks: "{{ .task.successful_tasks }}"

# Retry configuration
retry_policy:
  maximum_attempts: 3
  initial_interval: 1s
  maximum_interval: 30s

tasks:
  - id: resilient-task-1
    type: basic
    $use: tool(local::tools.#(id=="resilient-processor"))
    with:
      data: "{{ .workflow.input.data1 }}"

    # Individual error handling
    on_error:
      next: handle-individual-error
      with:
        task_id: "resilient-task-1"
        error: "{{ .task.error }}"

  - id: resilient-task-2
    type: basic
    $use: agent(local::agents.#(id=="resilient-agent"))
    action: process_safely
    with:
      data: "{{ .workflow.input.data2 }}"

    # Custom retry for this task
    retry_policy:
      maximum_attempts: 5
      initial_interval: 2s
```

</Tab>
</Tabs>

## Execution Strategies

### Wait All Strategy

The default strategy that waits for all tasks to complete:

```yaml
id: data-pipeline
type: parallel
strategy: wait_all
max_workers: 6
timeout: 15m

tasks:
  # Data extraction
  - id: extract-users
    type: basic
    $use: tool(local::tools.#(id=="database-client"))
    with:
      query: "SELECT * FROM users WHERE active = true"
      connection: "{{ .env.DB_CONNECTION }}"

  # Data processing
  - id: process-transactions
    type: basic
    $use: agent(local::agents.#(id=="transaction-processor"))
    action: analyze_transactions
    with:
      date_range: "{{ .workflow.input.date_range }}"

  # Report generation
  - id: generate-metrics
    type: basic
    $use: tool(local::tools.#(id=="metrics-generator"))
    with:
      metric_types: ["revenue", "users", "transactions"]
      period: "{{ .workflow.input.period }}"

# All tasks must complete before proceeding
on_success:
  next: combine-results
  with:
    users: "{{ .tasks.extract-users.output }}"
    transactions: "{{ .tasks.process-transactions.output }}"
    metrics: "{{ .tasks.generate-metrics.output }}"
```

### Race Strategy

First task to complete successfully wins:

```yaml
id: multi-provider-search
type: parallel
strategy: race
timeout: 10s

tasks:
  - id: search-provider-a
    type: basic
    $use: tool(local::tools.#(id=="search-api-a"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_A_KEY }}"

  - id: search-provider-b
    type: basic
    $use: tool(local::tools.#(id=="search-api-b"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_B_KEY }}"

  - id: search-provider-c
    type: basic
    $use: tool(local::tools.#(id=="search-api-c"))
    with:
      query: "{{ .workflow.input.search_query }}"
      api_key: "{{ .env.SEARCH_API_C_KEY }}"

# Uses result from first completing task
on_success:
  next: process-search-results
  with:
    results: "{{ .output }}"
    provider: "{{ .winner_task_id }}"
```

### Best Effort Strategy

Continue despite individual task failures:

```yaml
id: notification-broadcast
type: parallel
strategy: best_effort
timeout: 2m

tasks:
  - id: email-notification
    type: basic
    $use: tool(local::tools.#(id=="email-sender"))
    with:
      recipients: "{{ .workflow.input.email_recipients }}"
      subject: "{{ .workflow.input.subject }}"
      body: "{{ .workflow.input.message }}"

  - id: sms-notification
    type: basic
    $use: tool(local::tools.#(id=="sms-sender"))
    with:
      recipients: "{{ .workflow.input.phone_recipients }}"
      message: "{{ .workflow.input.short_message }}"

  - id: push-notification
    type: basic
    $use: tool(local::tools.#(id=="push-sender"))
    with:
      users: "{{ .workflow.input.app_users }}"
      title: "{{ .workflow.input.title }}"
      body: "{{ .workflow.input.message }}"

  - id: slack-notification
    type: basic
    $use: tool(local::tools.#(id=="slack-sender"))
    with:
      channel: "{{ .workflow.input.slack_channel }}"
      message: "{{ .workflow.input.message }}"

# Proceeds even if some notifications fail
on_success:
  next: log-notification-results
  with:
    successful_channels: "{{ .successful_tasks }}"
    failed_channels: "{{ .failed_tasks }}"
```

## Advanced Patterns

### Dynamic Task Generation

Create parallel tasks dynamically based on input:

```yaml
id: dynamic-parallel
type: parallel
strategy: wait_all
max_workers: 8

# Generate tasks from input array
tasks: "{{ range .workflow.input.items }}"
  - id: "process-{{ .id }}"
    type: basic
    $use: agent(local::agents.#(id=="item-processor"))
    action: process_item
    with:
      item_id: "{{ .id }}"
      item_data: "{{ .data }}"
      processing_options: "{{ .options }}"
"{{ end }}"

on_success:
  next: aggregate-results
  with:
    processing_results: "{{ .output }}"
    total_processed: "{{ len .output }}"
```

### Nested Parallel Processing

Combine parallel tasks with other task types:

```yaml
id: multi-level-processing
type: parallel
strategy: wait_all

tasks:
  # Single task
  - id: preprocess-data
    type: basic
    $use: tool(local::tools.#(id=="preprocessor"))
    with:
      data: "{{ .workflow.input.raw_data }}"

  # Nested parallel processing
  - id: parallel-analysis
    type: parallel
    strategy: wait_all
    max_workers: 4
    tasks:
      - id: sentiment-analysis
        type: basic
        $use: agent(local::agents.#(id=="sentiment-analyzer"))
        action: analyze_sentiment
        with:
          text: "{{ .workflow.input.text_data }}"

      - id: keyword-extraction
        type: basic
        $use: tool(local::tools.#(id=="keyword-extractor"))
        with:
          text: "{{ .workflow.input.text_data }}"

      - id: entity-recognition
        type: basic
        $use: agent(local::agents.#(id=="entity-recognizer"))
        action: extract_entities
        with:
          text: "{{ .workflow.input.text_data }}"

  # Collection processing
  - id: batch-processing
    type: collection
    items: "{{ .workflow.input.batch_items }}"
    mode: parallel
    task:
      id: "process-batch-item-{{ .index }}"
      type: basic
      $use: tool(local::tools.#(id=="batch-processor"))
      with:
        item: "{{ .item }}"
        index: "{{ .index }}"

on_success:
  next: final-aggregation
```

### Resource-Aware Parallel Processing

Adjust parallel execution based on available resources:

```yaml
id: resource-aware-parallel
type: parallel
strategy: wait_all

# Dynamic worker allocation
max_workers: "{{ .env.MAX_WORKERS | default 4 | toNumber }}"
worker_timeout: "{{ .env.WORKER_TIMEOUT | default '30s' }}"

# Resource monitoring
resource_limits:
  cpu_limit: "{{ .env.CPU_LIMIT | default '80%' }}"
  memory_limit: "{{ .env.MEMORY_LIMIT | default '1GB' }}"

tasks:
  - id: cpu-intensive-task
    type: basic
    resource_requirements:
      cpu: high
      memory: medium
    $use: tool(local::tools.#(id=="cpu-processor"))
    with:
      data: "{{ .workflow.input.cpu_data }}"

  - id: memory-intensive-task
    type: basic
    resource_requirements:
      cpu: low
      memory: high
    $use: tool(local::tools.#(id=="memory-processor"))
    with:
      data: "{{ .workflow.input.memory_data }}"

  - id: io-intensive-task
    type: basic
    resource_requirements:
      cpu: low
      memory: low
      io: high
    $use: tool(local::tools.#(id=="io-processor"))
    with:
      data: "{{ .workflow.input.io_data }}"
```

## Real-World Examples

### Example 1: Multi-Service Integration

<Steps>
<Step>

**Setup**: Configure parallel integration with multiple services

```yaml
id: multi-service-integration
type: parallel
strategy: wait_all
max_workers: 6
timeout: 5m

tasks:
  - id: fetch-user-profile
    type: basic
    $use: tool(local::tools.#(id=="user-service"))
    with:
      user_id: "{{ .workflow.input.user_id }}"
      endpoint: "/users/{{ .workflow.input.user_id }}"

  - id: fetch-user-preferences
    type: basic
    $use: tool(local::tools.#(id=="preferences-service"))
    with:
      user_id: "{{ .workflow.input.user_id }}"
      endpoint: "/preferences/{{ .workflow.input.user_id }}"

  - id: fetch-user-history
    type: basic
    $use: tool(local::tools.#(id=="history-service"))
    with:
      user_id: "{{ .workflow.input.user_id }}"
      limit: 100
      endpoint: "/history/{{ .workflow.input.user_id }}"

  - id: fetch-recommendations
    type: basic
    $use: agent(local::agents.#(id=="recommendation-engine"))
    action: generate_recommendations
    with:
      user_id: "{{ .workflow.input.user_id }}"
      context: "{{ .workflow.input.context }}"
```

</Step>
<Step>

**Process**: Aggregate results from all services

```yaml
on_success:
  next: merge-user-data
  with:
    user_data:
      profile: "{{ .tasks.fetch-user-profile.output }}"
      preferences: "{{ .tasks.fetch-user-preferences.output }}"
      history: "{{ .tasks.fetch-user-history.output }}"
      recommendations: "{{ .tasks.fetch-recommendations.output }}"
    metadata:
      fetch_time: "{{ now }}"
      user_id: "{{ .workflow.input.user_id }}"
```

</Step>
</Steps>

### Example 2: Content Processing Pipeline

```yaml
id: content-processing-pipeline
type: parallel
strategy: wait_all
max_workers: 8
timeout: 10m

tasks:
  # Text processing
  - id: extract-text
    type: basic
    $use: tool(local::tools.#(id=="text-extractor"))
    with:
      content: "{{ .workflow.input.content }}"
      format: "{{ .workflow.input.format }}"

  # Image processing
  - id: process-images
    type: basic
    $use: tool(local::tools.#(id=="image-processor"))
    with:
      images: "{{ .workflow.input.images }}"
      operations: ["resize", "optimize", "generate_alt_text"]

  # Metadata extraction
  - id: extract-metadata
    type: basic
    $use: agent(local::agents.#(id=="metadata-extractor"))
    action: extract_metadata
    with:
      content: "{{ .workflow.input.content }}"
      include_seo: true

  # Content validation
  - id: validate-content
    type: basic
    $use: agent(local::agents.#(id=="content-validator"))
    action: validate_content
    with:
      content: "{{ .workflow.input.content }}"
      rules: "{{ .workflow.input.validation_rules }}"

  # SEO analysis
  - id: analyze-seo
    type: basic
    $use: agent(local::agents.#(id=="seo-analyzer"))
    action: analyze_seo
    with:
      content: "{{ .workflow.input.content }}"
      target_keywords: "{{ .workflow.input.keywords }}"

outputs:
  processed_content:
    text: "{{ .tasks.extract-text.output }}"
    images: "{{ .tasks.process-images.output }}"
    metadata: "{{ .tasks.extract-metadata.output }}"
    validation: "{{ .tasks.validate-content.output }}"
    seo: "{{ .tasks.analyze-seo.output }}"

  processing_summary:
    total_time: "{{ .task.duration }}"
    tasks_completed: "{{ len .successful_tasks }}"
    tasks_failed: "{{ len .failed_tasks }}"
    success_rate: "{{ div (len .successful_tasks) (add (len .successful_tasks) (len .failed_tasks)) }}"
```

### Example 3: Data Validation Pipeline

```yaml
id: data-validation-pipeline
type: parallel
strategy: best_effort
max_workers: 4
timeout: 3m

tasks:
  # Schema validation
  - id: validate-schema
    type: basic
    $use: tool(local::tools.#(id=="schema-validator"))
    with:
      data: "{{ .workflow.input.data }}"
      schema: "{{ .workflow.input.schema }}"

    on_error:
      next: handle-schema-error
      with:
        validation_type: "schema"
        error: "{{ .task.error }}"

  # Business rules validation
  - id: validate-business-rules
    type: basic
    $use: agent(local::agents.#(id=="business-validator"))
    action: validate_business_rules
    with:
      data: "{{ .workflow.input.data }}"
      rules: "{{ .workflow.input.business_rules }}"

    on_error:
      next: handle-business-error
      with:
        validation_type: "business"
        error: "{{ .task.error }}"

  # Data quality checks
  - id: check-data-quality
    type: basic
    $use: tool(local::tools.#(id=="quality-checker"))
    with:
      data: "{{ .workflow.input.data }}"
      quality_metrics: ["completeness", "consistency", "accuracy"]

    on_error:
      next: handle-quality-error
      with:
        validation_type: "quality"
        error: "{{ .task.error }}"

  # Security validation
  - id: validate-security
    type: basic
    $use: agent(local::agents.#(id=="security-validator"))
    action: validate_security
    with:
      data: "{{ .workflow.input.data }}"
      security_rules: "{{ .workflow.input.security_rules }}"

    on_error:
      next: handle-security-error
      with:
        validation_type: "security"
        error: "{{ .task.error }}"

# Proceed with validation results
on_success:
  next: compile-validation-results
  with:
    validation_results:
      schema: "{{ .tasks.validate-schema.output }}"
      business: "{{ .tasks.validate-business-rules.output }}"
      quality: "{{ .tasks.check-data-quality.output }}"
      security: "{{ .tasks.validate-security.output }}"

    validation_summary:
      total_validations: 4
      successful_validations: "{{ len .successful_tasks }}"
      failed_validations: "{{ len .failed_tasks }}"
      overall_status: "{{ if .failed_tasks }}partial_success{{ else }}success{{ end }}"
```

## Performance Considerations

### Optimal Worker Configuration

```yaml
# CPU-bound tasks
id: cpu-bound-parallel
type: parallel
strategy: wait_all
max_workers: "{{ .env.CPU_CORES | default 4 }}"  # Match CPU cores
timeout: 30m

# I/O-bound tasks
id: io-bound-parallel
type: parallel
strategy: wait_all
max_workers: "{{ mul (.env.CPU_CORES | default 4) 2 }}"  # 2x CPU cores
timeout: 5m

# Mixed workload
id: mixed-workload-parallel
type: parallel
strategy: wait_all
max_workers: 8
timeout: 10m
```

### Memory Management

```yaml
id: memory-efficient-parallel
type: parallel
strategy: wait_all
max_workers: 4

# Configure memory limits
resource_limits:
  memory_per_worker: "256MB"
  total_memory_limit: "1GB"

tasks:
  - id: memory-conscious-task
    type: basic
    $use: tool(local::tools.#(id=="efficient-processor"))
    with:
      # Process data in chunks
      data: "{{ .workflow.input.data | chunk 1000 }}"
      memory_limit: "128MB"
```

## Best Practices

1. **Choose the Right Strategy**: Use `wait_all` for dependent results, `race` for redundancy, `best_effort` for optional operations
2. **Set Appropriate Timeouts**: Balance responsiveness with operation requirements
3. **Monitor Resource Usage**: Configure workers based on available CPU/memory
4. **Handle Failures Gracefully**: Design for partial failure scenarios
5. **Optimize Task Granularity**: Balance parallel efficiency with overhead

Parallel processing enables Compozy workflows to scale efficiently and handle complex, concurrent operations while maintaining reliability and performance control.
