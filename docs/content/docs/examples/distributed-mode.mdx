---
title: "Distributed Mode Example"
description: "Production-ready configuration wired to managed infrastructure."
icon: Server
---

Distributed mode connects Compozy to external PostgreSQL, Temporal, and Redis clusters. The example assumes managed services with TLS and environment-driven secrets so it is safe to commit.

```yaml title="examples/configs/distributed-mode.yaml"
# Production profile for multi-tenant or scale-out deployments.
name: prod-orchestration
version: "1.0.0"
mode: distributed  # Use managed services for database, Temporal, and Redis.

# PostgreSQL with pgvector support hosted outside the process.
database:
  driver: postgres
  url: "${COMPOZY_DATABASE_URL}"  # Prefer a single URL env var for rotate-friendly credentials.
  migrations:
    schema: compozy  # Isolate migration history from other applications.

# Connect to a remote Temporal cluster with explicit namespace and TLS.
temporal:
  mode: remote  # Resolved automatically when global mode is distributed.
  host_port: temporal.prod.internal:7233
  namespace: compozy-prod
  tls:
    enabled: true
    ca_file: "/etc/compozy/certs/temporal-ca.pem"
    cert_file: "${TEMPORAL_TLS_CERT}"
    key_file: "${TEMPORAL_TLS_KEY}"

# Redis cluster for durable caching and signals with optional TLS.
redis:
  mode: distributed
  distributed:
    addr: redis.prod.internal:6379
    username: compozy
    password: "${REDIS_PASSWORD}"
    tls:
      enabled: true
      ca_file: "/etc/compozy/certs/redis-ca.pem"

# Multiple models with explicit routing for production workloads.
models:
  - provider: openai
    model: gpt-4o
    api_key: "${OPENAI_API_KEY}"
  - provider: anthropic
    model: claude-3-5-sonnet-latest
    api_key: "${ANTHROPIC_API_KEY}"

# Reference a workflow file that exercises multiple providers.
workflows:
  - source: ./workflows/support-router.yaml

# Representative tasks showing cross-model selection.
tasks:
  - id: classify
    type: basic
    action: run
    prompt: "Classify the following ticket: {{ .workflow.input.ticket }}"
    provider: openai
  - id: escalate
    type: basic
    action: run
    prompt: "Draft a high-touch reply for: {{ .tasks.classify.output }}"
    provider: anthropic
    final: true
```

## Operational Checklist

- Confirm VPC connectivity or service endpoints for PostgreSQL, Temporal, and Redis.
- Populate the referenced environment variables in your secret manager or deployment platform.
- Mount TLS material (if required) and update paths when packaging containers.

```yaml title="workflows/support-router.yaml"
id: support-router
version: 1.0.0
description: Production triage workflow that routes tickets through multiple models

config:
  input:
    type: object
    properties:
      ticket:
        type: string
        description: Full support ticket text to classify and answer
    required:
      - ticket

tasks:
  - id: classify
    type: reference
    target: classify
  - id: escalate
    type: reference
    target: escalate

outputs:
  classification: "{{ .tasks.classify.output }}"
  reply: "{{ .tasks.escalate.output }}"
```

## When to Use Distributed Mode

- Production environments where uptime, durability, and concurrency matter most
- Shared staging clusters that mirror production topologies
- Large teams that need predictable access to centralized infrastructure

<Callout type="warning">
Distributed mode surfaces validation errors if SQLite-only features (like `pgvector`) are enabled or TLS files are missing. Run `compozy config diagnostics` before deploying to catch misconfigurations early.
</Callout>
