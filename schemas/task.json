{
  "$defs": {
    "Attachments": {
      "description": "Attachments is a slice of polymorphic Attachment values with custom decoding.",
      "items": true,
      "type": "array"
    },
    "ClearConfig": {
      "additionalProperties": false,
      "description": "ClearConfig controls memory clearing behavior",
      "properties": {
        "backup": {
          "description": "Backup data before clearing\nImplementation-dependent, may not be available for all backends",
          "type": "boolean"
        },
        "confirm": {
          "description": "Confirm must be true to execute clear operation\nRequired safety check to prevent accidental data loss",
          "type": "boolean"
        }
      },
      "type": "object"
    },
    "EnvMap": {
      "additionalProperties": {
        "type": "string"
      },
      "type": "object"
    },
    "ErrorTransition": {
      "additionalProperties": false,
      "description": "ErrorTransition defines error handling behavior when a task fails.",
      "properties": {
        "next": {
          "description": "ID of the error handler task\n\n- **Example**: \"handle-error\", \"retry-with-fallback\"",
          "type": "string"
        },
        "with": {
          "$ref": "#/$defs/Input",
          "description": "Error context passed to the handler\nIncludes error details: { \"error\": \"{{ .error }}\", \"attempt\": \"{{ .retryCount }}\" }"
        }
      },
      "type": "object"
    },
    "FlushConfig": {
      "additionalProperties": false,
      "description": "FlushConfig controls memory flushing behavior",
      "properties": {
        "dry_run": {
          "description": "DryRun simulates flush without actually removing data\nUseful for testing what would be removed",
          "type": "boolean"
        },
        "force": {
          "description": "Force flush even if below threshold\nBypasses normal threshold checks",
          "type": "boolean"
        },
        "max_keys": {
          "description": "Maximum number of keys to flush in one operation\nDefault: 100",
          "type": "integer"
        },
        "strategy": {
          "description": "Strategy for selecting keys to flush\nOptions: \"simple_fifo\" (oldest first), \"lru\" (least recently used)\nDefault: \"simple_fifo\"",
          "type": "string"
        },
        "threshold": {
          "description": "Threshold (0-1) for triggering flush based on memory usage\n- **Example**: 0.8 means flush when 80% full",
          "type": "number"
        }
      },
      "type": "object"
    },
    "GlobalOpts": {
      "additionalProperties": false,
      "description": "GlobalOpts contains workflow execution options that can be configured at multiple levels.",
      "properties": {
        "heartbeat_timeout": {
          "description": "Interval for task heartbeat signals\nUsed for long-running tasks to indicate progress\n\n- **Example**: \"10s\", \"30s\", \"1m\"",
          "type": "string"
        },
        "on_error": {
          "$ref": "#/$defs/ErrorTransition",
          "description": "Error handler configuration\nDefines what happens when a task fails after all retries"
        },
        "retry_policy": {
          "$ref": "#/$defs/RetryPolicyConfig",
          "description": "Retry configuration for transient failures\nAutomatically retries failed tasks with exponential backoff"
        },
        "schedule_to_close_timeout": {
          "description": "Total timeout from scheduling to completion\nDefault: \"6m\"\n\n- **Example**: \"1m\", \"15m\", \"2h\"",
          "type": "string"
        },
        "schedule_to_start_timeout": {
          "description": "Maximum time to wait for a task to start executing\nDefault: \"1m\"\n\n- **Example**: \"30s\", \"5m\", \"1h\"",
          "type": "string"
        },
        "start_to_close_timeout": {
          "description": "Maximum time for task execution once started\nDefault: \"5m\"\n\n- **Example**: \"30s\", \"10m\", \"1h\"",
          "type": "string"
        }
      },
      "type": "object"
    },
    "HealthConfig": {
      "additionalProperties": false,
      "description": "HealthConfig controls health check behavior",
      "properties": {
        "check_connectivity": {
          "description": "CheckConnectivity verifies connection to memory backend\nTests actual read/write operations",
          "type": "boolean"
        },
        "include_stats": {
          "description": "IncludeStats adds memory statistics to health check results\nProvides additional diagnostic information",
          "type": "boolean"
        }
      },
      "type": "object"
    },
    "Input": {
      "type": "object"
    },
    "MemoryReference": {
      "additionalProperties": false,
      "description": "MemoryReference is used in Agent configuration to point to a MemoryResource and define how the agent interacts with it.",
      "properties": {
        "id": {
          "type": "string"
        },
        "key": {
          "description": "Key is a template string that resolves to the actual memory instance key.\ne.g., \"support-{{ .workflow.input.conversationId }}\"",
          "type": "string"
        },
        "mode": {
          "description": "Mode defines access permissions (e.g., \"read-write\", \"read-only\").",
          "type": "string"
        }
      },
      "type": "object"
    },
    "PathCWD": {
      "additionalProperties": false,
      "properties": {
        "path": {
          "description": "Path holds the absolute working directory.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "PromptParams": {
      "additionalProperties": false,
      "description": "PromptParams defines the parameters that control LLM behavior during text generation.",
      "properties": {
        "max_length": {
          "description": "MaxLength provides an alternative way to specify maximum response length.\nTypically used by providers that distinguish between length and token limits.\n- **Range**: MinLength to provider-specific maximum\n- **Provider Support**: Primarily local models and some API providers",
          "type": "integer"
        },
        "max_tokens": {
          "description": "MaxTokens limits the maximum number of tokens in the generated response.\nThis parameter is crucial for cost control and response time management.\n- **Range**: 1 to model-specific maximum (e.g., 8192 for GPT-4)\n- **Default**: Provider-specific default (typically 1000-2000)",
          "type": "integer"
        },
        "min_length": {
          "description": "MinLength specifies the minimum number of tokens that must be generated.\nPrevents the model from generating responses that are too short.\n- **Range**: 1 to MaxTokens\n- **Provider Support**: Limited; primarily local models",
          "type": "integer"
        },
        "repetition_penalty": {
          "description": "RepetitionPenalty reduces the likelihood of repeating the same tokens.\nValues \u003e 1.0 penalize repetition, values \u003c 1.0 encourage it.\n- **Range**: 0.1 to 2.0\n- **Recommended**: 1.0 (no penalty) to 1.2 (moderate penalty)\n- **Provider Support**: Primarily local models (Ollama, etc.)",
          "type": "number"
        },
        "seed": {
          "description": "Seed provides a random seed for reproducible outputs.\nWhen set, the same input with the same parameters will generate identical responses.\n- **Use Cases**: Testing, debugging, demonstration, A/B testing\n\u003e **Note:**: Not all providers support seeding; OpenAI and some others do",
          "type": "integer"
        },
        "stop_words": {
          "description": "StopWords defines a list of strings that will halt text generation when encountered.\nUseful for creating structured outputs or preventing unwanted content patterns.\n\n- **Example**: `[\"END\", \"STOP\", \"\\n\\n---\"]` for section-based content\n\u003e **Note:**: Not all providers support stop words; check provider documentation",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "temperature": {
          "description": "Temperature controls the randomness of the generated text.\nLower values produce more deterministic, focused responses.\nHigher values increase creativity and variation but may reduce coherence.\n- **Range**: 0.0 (deterministic) to 1.0 (maximum randomness)\n- **Recommended**: 0.1-0.3 for factual tasks, 0.7-0.9 for creative tasks",
          "type": "number"
        },
        "top_k": {
          "description": "TopK limits the number of highest probability tokens considered during sampling.\nLower values focus on the most likely tokens, higher values allow more variety.\n- **Range**: 1 to vocabulary size (typically 1-100)\n- **Provider Support**: Primarily Google models and some local models",
          "type": "integer"
        },
        "top_p": {
          "description": "TopP (nucleus sampling) considers only tokens with cumulative probability up to this value.\nDynamically adjusts the vocabulary size based on probability distribution.\n- **Range**: 0.0 to 1.0\n- **Recommended**: 0.9 for balanced outputs, 0.95 for more variety",
          "type": "number"
        }
      },
      "type": "object"
    },
    "ProviderConfig": {
      "additionalProperties": false,
      "description": "ProviderConfig represents the complete configuration for an LLM provider in Compozy workflows.",
      "properties": {
        "api_key": {
          "description": "APIKey contains the authentication key for the AI provider.\n\n- **Security**: Use template references to environment variables.\n- **Examples**: `\"{{ .env.OPENAI_API_KEY }}\"`, `\"{{ .secrets.ANTHROPIC_KEY }}\"`\n\u003e **Note:**: Required for most cloud providers, optional for local providers",
          "type": "string"
        },
        "api_url": {
          "description": "APIURL specifies a custom API endpoint for the provider.\n**Use Cases**:\n  - Local model hosting (Ollama, OpenAI-compatible servers)\n  - Enterprise API gateways\n  - Regional API endpoints\n  - Custom proxy servers\n\n**Examples**: `\"http://localhost:11434\"`, `\"https://api.openai.com/v1\"`",
          "type": "string"
        },
        "default": {
          "description": "Default indicates that this model should be used as the fallback when no explicit\nmodel configuration is provided at the task or agent level.\n\n**Behavior**:\n  - Only one model per project can be marked as default\n  - When set to true, this model will be used for tasks/agents without explicit model config\n  - Validation ensures at most one default model per project\n\n**Example**:\n```yaml\nmodels:\n  - provider: openai\n    model: gpt-4\n    default: true  # This will be used by default\n```",
          "type": "boolean"
        },
        "max_tool_iterations": {
          "description": "MaxToolIterations optionally caps the maximum number of tool-call iterations\nduring a single LLM request when tools are available.\nWhen \u003e 0, overrides the global default for this model; 0 uses the global default.",
          "type": "integer"
        },
        "model": {
          "description": "Model defines the specific model identifier to use with the provider.\nModel names are provider-specific and determine capabilities and pricing.\n\n- **Examples**:\n  - OpenAI: `\"gpt-4-turbo\"`, `\"gpt-3.5-turbo\"`\n  - Anthropic: `\"claude-4-opus\"`, `\"claude-3-5-haiku-latest\"`\n  - Google: `\"gemini-pro\"`, `\"gemini-pro-vision\"`\n  - Ollama: `\"llama2:13b\"`, `\"mistral:7b\"`",
          "type": "string"
        },
        "organization": {
          "description": "Organization specifies the organization ID for providers that support it.\n- **Primary Use**: OpenAI organization management for billing and access control\n\n- **Example**: `\"org-123456789abcdef\"`\n\u003e **Note:**: Optional for most providers",
          "type": "string"
        },
        "params": {
          "$ref": "#/$defs/PromptParams",
          "description": "Params contains the generation parameters that control LLM behavior.\nThese parameters are applied to all requests using this provider configuration.\nCan be overridden at the task or action level for specific requirements."
        },
        "provider": {
          "description": "Provider specifies which AI service to use for LLM operations.\nMust match one of the supported ProviderName constants.\n\n- **Examples**: `\"openai\"`, `\"anthropic\"`, `\"google\"`, `\"ollama\"`",
          "type": "string"
        }
      },
      "type": "object"
    },
    "RetryPolicyConfig": {
      "additionalProperties": false,
      "description": "RetryPolicyConfig defines automatic retry behavior for failed tasks.",
      "properties": {
        "backoff_coefficient": {
          "description": "Multiplier for exponential backoff\n- **Default:** `2.0` (doubles each time)\n- **Example:** `1.5`, `2.0`, `3.0`",
          "type": "number"
        },
        "initial_interval": {
          "description": "Initial delay before first retry\n- **Default:** `\"1s\"`\n- **Example:** `\"500ms\"`, `\"2s\"`, `\"1m\"`",
          "type": "string"
        },
        "maximum_attempts": {
          "description": "Maximum retry attempts\n- **Default:** `3`\n- **Example:** `5` for critical operations",
          "type": "integer"
        },
        "maximum_interval": {
          "description": "Maximum delay between retries\n- **Default:** `\"1m\"`\n- **Example:** `\"30s\"`, `\"5m\"`, `\"1h\"`",
          "type": "string"
        },
        "non_retryable_error_types": {
          "description": "Error types that should not trigger retries\n- **Example:** `[\"ValidationError\", \"AuthenticationError\"]`",
          "items": {
            "type": "string"
          },
          "type": "array"
        }
      },
      "type": "object"
    },
    "Schema": {
      "type": "object"
    },
    "SignalConfig": {
      "additionalProperties": false,
      "description": "SignalConfig defines the signal to be sent",
      "properties": {
        "id": {
          "description": "ID is the unique identifier for the signal\nWait tasks with matching wait_for values will receive this signal\n- **Example**: \"user-approved\", \"payment-completed\", \"data-ready\"",
          "type": "string"
        },
        "payload": {
          "description": "Payload contains data to send with the signal\nThis data is available to the receiving wait task for processing\nCan be any JSON-serializable data structure\n- **Example**: { \"user_id\": \"123\", \"status\": \"approved\", \"timestamp\": \"2024-01-01T00:00:00Z\" }",
          "type": "object"
        }
      },
      "type": "object"
    },
    "StatsConfig": {
      "additionalProperties": false,
      "description": "StatsConfig controls statistics gathering",
      "properties": {
        "group_by": {
          "description": "GroupBy field for aggregating statistics\n- **Example**: \"user\", \"session\", \"workflow\"\nGroups stats by the specified field in stored data",
          "type": "string"
        },
        "include_content": {
          "description": "IncludeContent includes actual memory content in stats\nWARNING: May return large amounts of data",
          "type": "boolean"
        }
      },
      "type": "object"
    },
    "SuccessTransition": {
      "additionalProperties": false,
      "description": "SuccessTransition defines the next task to execute after successful completion.",
      "properties": {
        "next": {
          "description": "ID of the next task to execute\n- **Example:** `\"process-results\"`, `\"send-notification\"`",
          "type": "string"
        },
        "with": {
          "$ref": "#/$defs/Input",
          "description": "Input parameters to pass to the next task\n- **Supports:** Template expressions like `{ \"data\": \"{{ .output.result }}\" }`"
        }
      },
      "type": "object"
    }
  },
  "$id": "task.json",
  "$schema": "http://json-schema.org/draft-07/schema#",
  "additionalProperties": false,
  "description": "Config is the main task configuration structure in Compozy.",
  "properties": {
    "action": {
      "description": "Action identifier that describes what this task does\nUsed for logging and debugging purposes\n- **Example**: \"process-user-data\", \"send-notification\"",
      "type": "string"
    },
    "agent": {
      "$ref": "agent.json",
      "description": "Agent configuration for AI-powered task execution\nOnly used when the task needs to interact with an LLM agent\nMutually exclusive with Tool field\n$ref: schema://agents"
    },
    "attachments": {
      "$ref": "#/$defs/Attachments",
      "description": "Attachments declared at the task scope are available to all nested agents/actions."
    },
    "batch": {
      "description": "Batch size for processing items in groups (0 = no batching)\nUseful for rate limiting or managing resource usage\n- **Example**: 10 means process 10 items at a time",
      "type": "integer"
    },
    "batch_size": {
      "description": "BatchSize for operations that process multiple keys\nControls how many keys are processed in each batch\nDefault: 100, Maximum: 10,000",
      "type": "integer"
    },
    "clear_config": {
      "$ref": "#/$defs/ClearConfig",
      "description": "Configuration for clear operations\nOnly used when operation is \"clear\""
    },
    "condition": {
      "description": "CEL expression for conditional task execution or routing decisions\nTask only executes if condition evaluates to true\n- **Example**: \"input.status == 'approved' \u0026\u0026 input.amount \u003e 1000\"",
      "type": "string"
    },
    "config": {
      "$ref": "#/$defs/GlobalOpts",
      "description": "Global configuration options inherited from parent contexts\nIncludes provider settings, API keys, and other global parameters"
    },
    "env": {
      "$ref": "#/$defs/EnvMap",
      "description": "Environment variables available during task execution\nCan override or extend workflow-level environment variables\n- **Example**: { \"API_KEY\": \"{{ .env.SECRET_KEY }}\" }"
    },
    "file_path": {
      "description": "Absolute file path where this task configuration was loaded from\nSet automatically during configuration loading",
      "type": "string"
    },
    "filter": {
      "description": "Filter is an optional CEL expression to filter items before processing\nEach item is available as 'item' in the expression\n- **Example**: \"item.status != 'inactive'\" or \"item.age \u003e 18\"",
      "type": "string"
    },
    "final": {
      "description": "Marks this task as a terminal node in the workflow\nNo subsequent tasks will execute after a final task",
      "type": "boolean"
    },
    "flush_config": {
      "$ref": "#/$defs/FlushConfig",
      "description": "Configuration for flush operations\nOnly used when operation is \"flush\""
    },
    "health_config": {
      "$ref": "#/$defs/HealthConfig",
      "description": "Configuration for health check operations\nOnly used when operation is \"health\""
    },
    "id": {
      "description": "Unique identifier for the task instance within a workflow\nMust be unique within the workflow scope",
      "type": "string"
    },
    "index_var": {
      "description": "IndexVar is the variable name for the current index (default: \"index\")\nAvailable in task templates as {{ .index }} or custom name\nZero-based index of the current item",
      "type": "string"
    },
    "input": {
      "$ref": "#/$defs/Schema",
      "description": "Schema definition for validating task input parameters\nFollows JSON Schema specification for type validation\nFormat:\n  type: object\n  properties:\n    user_id: { type: string, description: \"User identifier\" }\n  required: [\"user_id\"]"
    },
    "item_var": {
      "description": "ItemVar is the variable name for the current item (default: \"item\")\nAvailable in task templates as {{ .item }} or custom name\n- **Example**: Set to \"user\" to access as {{ .user }} in templates",
      "type": "string"
    },
    "items": {
      "description": "Items is a template expression that evaluates to an array\nThe expression should resolve to a list of items to iterate over\n- **Example**: \"{{ .workflow.input.users }}\" or \"{{ range(1, 10) }}\"",
      "type": "string"
    },
    "json_mode": {
      "description": "Forces the agent to always respond in valid JSON format.\nWhen enabled, the agent's responses must be parseable JSON objects.\n\n**Use cases:**\n- API integrations requiring structured data\n- Automated processing of agent outputs\n- Ensuring consistent response formats\n\n⚠️ **Note:** May limit the agent's ability to provide explanatory text",
      "type": "boolean"
    },
    "key_template": {
      "description": "KeyTemplate is a template expression for the memory key\nSupports template variables for dynamic key generation\n- **Example**: \"user:{{ .workflow.input.user_id }}:profile\"",
      "type": "string"
    },
    "max_iterations": {
      "description": "Maximum number of reasoning iterations the agent can perform.\nThe agent may self-correct and refine its response across multiple iterations\nto improve accuracy and address complex multi-step problems.\n\n**Default:** `5` iterations\n\n**Trade-offs:**\n- Higher values enable more thorough problem-solving and self-correction\n- Each iteration consumes additional tokens and increases response latency\n- Configure based on task complexity, accuracy requirements, and cost constraints",
      "type": "integer"
    },
    "max_keys": {
      "description": "MaxKeys limits the number of keys processed\nSafety limit to prevent runaway operations\nDefault: 1,000, Maximum: 50,000",
      "type": "integer"
    },
    "max_workers": {
      "description": "MaxWorkers limits the number of concurrent task executions\n0 means no limit (all tasks run concurrently)\n- **Example**: 5 means at most 5 tasks run at the same time",
      "type": "integer"
    },
    "mcps": {
      "description": "Model Context Protocol (MCP) server configurations.\nMCPs provide standardized interfaces for extending agent capabilities\nwith external services and data sources through protocol-based communication.\n\n**Common MCP integrations:**\n- Database connectors (PostgreSQL, Redis, MongoDB)\n- Search engines (Elasticsearch, Solr)\n- Knowledge bases (vector databases, documentation systems)\n- External APIs (REST, GraphQL, gRPC services)\n\nMCPs support both stdio and HTTP transport protocols.",
      "items": {
        "$ref": "mcp.json"
      },
      "type": "array"
    },
    "memory": {
      "description": "Memory references enabling the agent to access persistent context.\nMemory provides stateful interactions across workflow steps and sessions.\n\n**Configuration format:**\n```yaml\nmemory:\n  - id: \"user_context\"           # Memory resource ID\n    key: \"user:{{.user_id}}\"     # Dynamic key with template\n    mode: \"read-write\"           # Access mode (default: \"read-write\")\n```\n\n**Access modes:**\n- `\"read-write\"`: Full access to read and modify memory\n- `\"read-only\"`: Can only read existing memory entries",
      "items": {
        "$ref": "#/$defs/MemoryReference"
      },
      "type": "array"
    },
    "memory_ref": {
      "description": "MemoryRef identifies which memory store to use\nReferences a memory configuration defined at the project level\n- **Example**: \"user-sessions\", \"workflow-state\", \"cache\"",
      "type": "string"
    },
    "mode": {
      "description": "Mode determines if items are processed in parallel or sequentially\nDefaults to \"parallel\"\nOptions: parallel, sequential",
      "type": "string"
    },
    "model_config": {
      "$ref": "#/$defs/ProviderConfig",
      "description": "LLM provider configuration defining which AI model to use and its parameters.\nSupports multiple providers including OpenAI, Anthropic, Google, Groq, and local models.\n\n**Required fields:** provider, model\n**Optional fields:** api_key, api_url, params (temperature, max_tokens, etc.)"
    },
    "on_error": {
      "$ref": "#/$defs/ErrorTransition",
      "description": "Error handling configuration\nDefines fallback behavior when task execution fails\nCan specify error task ID or retry configuration"
    },
    "on_success": {
      "$ref": "#/$defs/SuccessTransition",
      "description": "Task execution control\nDefines what happens after successful task completion\nCan specify next task ID or conditional routing"
    },
    "on_timeout": {
      "description": "OnTimeout specifies the next task to execute if the wait times out\nUses the timeout value from BaseConfig\nIf not specified, the task fails on timeout",
      "type": "string"
    },
    "operation": {
      "description": "Operation type to perform on memory\nRequired field that determines the action to take",
      "type": "string"
    },
    "output": {
      "$ref": "#/$defs/Schema",
      "description": "Schema definition for validating task output data\nEnsures task results conform to expected structure\nUses same format as InputSchema"
    },
    "outputs": {
      "$ref": "#/$defs/Input",
      "description": "Output mappings that define what data this task exposes to subsequent tasks\nUses template expressions to transform task results\n- **Example**: { \"processed_data\": \"{{ .task.output.result }}\" }"
    },
    "payload": {
      "description": "Payload data for write/append operations\nCan be any JSON-serializable data structure\nRequired for write and append operations"
    },
    "processor": {
      "$ref": "#",
      "description": "Processor is an optional task configuration to process received signals\nAllows custom handling of signal data before continuing\nThe processor receives the signal payload as input\n$ref: inline:#"
    },
    "prompt": {
      "description": "Prompt provides direct instruction to agents when no specific action is needed\nUsed for ad-hoc agent interactions without predefined action definitions\n- **Example**: \"Analyze this code for security issues\", \"Summarize the following text\"",
      "type": "string"
    },
    "resource": {
      "description": "Resource reference for the task\nFormat: \"compozy:task:\u003cname\u003e\" (e.g., \"compozy:task:process-data\")",
      "type": "string"
    },
    "retries": {
      "description": "Number of retry attempts for failed task executions\nDefault: 0 (no retries)",
      "type": "integer"
    },
    "routes": {
      "description": "Routes maps condition values to task IDs or inline task configurations\nThe condition field in BaseConfig is evaluated, and its result is used\nas the key to select the appropriate route\nValues can be:\n  - Task ID (string): References an existing task\n  - Inline task config (object): Defines task configuration directly\n- **Example**:\n  routes:\n    approved: \"process-payment\"  # Task ID reference\n    rejected:                    # Inline task config\n      type: basic\n      agent: { id: rejection-handler }\n    pending: \"wait-for-approval\"",
      "type": "object"
    },
    "signal": {
      "$ref": "#/$defs/SignalConfig",
      "description": "Signal configuration containing the signal ID and payload"
    },
    "sleep": {
      "description": "Sleep duration after task completion\nFormat: \"5s\", \"1m\", \"500ms\", \"1h30m\"\nUseful for rate limiting or giving external systems time to process",
      "type": "string"
    },
    "stats_config": {
      "$ref": "#/$defs/StatsConfig",
      "description": "Configuration for statistics operations\nOnly used when operation is \"stats\""
    },
    "strategy": {
      "description": "Strategy determines how the parallel execution handles task completion\nDefaults to \"wait_all\" if not specified\nOptions: wait_all, fail_fast, best_effort, race",
      "type": "string"
    },
    "task": {
      "$ref": "#",
      "description": "Task template for collection tasks\nThis configuration is replicated for each item in the collection\nThe item and index are available as template variables\n$ref: inline:#"
    },
    "tasks": {
      "description": "Tasks array for parallel, composite, and collection tasks\nContains the list of sub-tasks to execute\nFor parallel: tasks run concurrently\nFor composite: tasks run sequentially\nFor collection: not used (use Task field instead)\n$ref: inline:#",
      "items": {
        "$ref": "#"
      },
      "type": "array"
    },
    "timeout": {
      "description": "Maximum execution time for parallel or composite tasks\nFormat: \"30s\", \"5m\", \"1h\"\nTask will be canceled if it exceeds this duration",
      "type": "string"
    },
    "tool": {
      "$ref": "tool.json",
      "description": "Tool configuration for executing specific tool operations\nUsed when the task needs to execute a predefined tool\nMutually exclusive with Agent field\n$ref: schema://tools"
    },
    "tools": {
      "description": "Tools available to the agent for extending its capabilities.\nWhen tools are defined, the agent automatically has `toolChoice` set to `\"auto\"`,\nenabling autonomous tool selection and invocation during task execution.\n\n**Tool types supported:**\n- File system operations (read, write, list)\n- API integrations (HTTP requests, webhooks)\n- Data processing utilities (parsing, transformation)\n- Custom business logic (TypeScript/JavaScript execution)\n\nTools are referenced by ID and can be shared across multiple agents.",
      "items": {
        "$ref": "tool.json"
      },
      "type": "array"
    },
    "type": {
      "description": "Type of task that determines execution behavior\nIf not specified, defaults to \"basic\"",
      "type": "string"
    },
    "wait_for": {
      "description": "WaitFor specifies the signal ID to wait for\nThe task will pause until a signal with this ID is received\nMust match the ID used in a SignalTask\n- **Example**: \"user-approved\", \"payment-completed\"",
      "type": "string"
    },
    "with": {
      "$ref": "#/$defs/Input",
      "description": "Input parameters passed to the task at execution time\nCan include references to workflow inputs, previous task outputs, etc.\n- **Example**: { \"user_id\": \"{{ .workflow.input.user_id }}\" }"
    }
  },
  "type": "object",
  "yamlCompatible": true
}
