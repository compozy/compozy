{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://schemas.compozy.dev/memory.json",
  "$defs": {
    "CircuitBreakerConfig": {
      "properties": {
        "enabled": {
          "type": "boolean"
        },
        "timeout": {
          "type": "string",
          "description": "e.g., \"100ms\""
        },
        "max_failures": {
          "type": "integer"
        },
        "reset_timeout": {
          "type": "string",
          "description": "e.g., \"30s\""
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "CircuitBreakerConfig defines parameters for a circuit breaker pattern."
    },
    "FlushingStrategyConfig": {
      "properties": {
        "type": {
          "type": "string",
          "description": "Type is the kind of flushing strategy to apply (e.g., hybrid_summary)."
        },
        "summarize_threshold": {
          "type": "number",
          "description": "SummarizeThreshold is the percentage of MaxTokens/MaxMessages at which summarization should trigger.\nE.g., 0.8 means trigger summarization when memory is 80% full. Only for hybrid_summary."
        },
        "summary_tokens": {
          "type": "integer",
          "description": "SummaryTokens is the target token count for generated summaries. Only for hybrid_summary."
        },
        "summarize_oldest_percent": {
          "type": "number",
          "description": "SummarizeOldestPercent is the percentage of the oldest messages to summarize. Only for hybrid_summary.\nE.g., 0.3 means summarize the oldest 30% of messages."
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "FlushingStrategyConfig holds the configuration for how memory is flushed or trimmed."
    },
    "LockConfig": {
      "properties": {
        "append_ttl": {
          "type": "string",
          "description": "AppendTTL is the lock timeout for append operations (default: \"30s\")"
        },
        "clear_ttl": {
          "type": "string",
          "description": "ClearTTL is the lock timeout for clear operations (default: \"10s\")"
        },
        "flush_ttl": {
          "type": "string",
          "description": "FlushTTL is the lock timeout for flush operations (default: \"5m\")"
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "LockConfig defines lock timeout settings for memory operations."
    },
    "PersistenceConfig": {
      "properties": {
        "type": {
          "type": "string"
        },
        "ttl": {
          "type": "string",
          "description": "TTL is the time-to-live for memory instances in this resource.\nParsed as a duration string (e.g., \"24h\", \"30m\")."
        },
        "circuit_breaker": {
          "$ref": "#/$defs/CircuitBreakerConfig",
          "description": "CircuitBreaker configures resilience for persistence operations."
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "PersistenceConfig defines how memory instances are persisted."
    },
    "PrivacyPolicyConfig": {
      "properties": {
        "redact_patterns": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "RedactPatterns is a list of regex patterns to apply for redacting content."
        },
        "non_persistable_message_types": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "NonPersistableMessageTypes is a list of message types/roles that should not be persisted."
        },
        "default_redaction_string": {
          "type": "string",
          "description": "DefaultRedactionString is the string to replace redacted content with. Defaults to \"[REDACTED]\"."
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "PrivacyPolicyConfig defines rules for handling sensitive data."
    },
    "TokenAllocation": {
      "properties": {
        "short_term": {
          "type": "number",
          "description": "ShortTerm is the percentage of tokens allocated for recent messages."
        },
        "long_term": {
          "type": "number",
          "description": "LongTerm is the percentage of tokens allocated for summarized or older important context."
        },
        "system": {
          "type": "number",
          "description": "System is the percentage of tokens reserved for system prompts or critical instructions."
        },
        "user_defined": {
          "additionalProperties": {
            "type": "number"
          },
          "type": "object",
          "description": "UserDefined is a map for additional custom allocations if needed."
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "TokenAllocation defines percentages for distributing a token budget across different categories of memory content."
    },
    "TokenProviderConfig": {
      "properties": {
        "provider": {
          "type": "string",
          "description": "\"openai\", \"anthropic\", etc."
        },
        "model": {
          "type": "string",
          "description": "Model name"
        },
        "api_key": {
          "type": "string",
          "description": "API key for real-time counting (can be env var reference like ${OPENAI_API_KEY})"
        },
        "api_key_env": {
          "type": "string",
          "description": "Environment variable name containing the API key"
        },
        "endpoint": {
          "type": "string",
          "description": "Optional custom endpoint"
        },
        "fallback": {
          "type": "string",
          "description": "Fallback strategy"
        },
        "settings": {
          "additionalProperties": {
            "type": "string"
          },
          "type": "object",
          "description": "Provider-specific settings"
        }
      },
      "additionalProperties": false,
      "type": "object",
      "description": "TokenProviderConfig defines configuration for multi-provider token counting"
    }
  },
  "properties": {
    "resource": {
      "type": "string",
      "description": "Resource type identifier, **must be \"memory\"**.\nThis field is used by the autoloader system to identify and properly\nregister this configuration as a memory resource."
    },
    "id": {
      "type": "string",
      "description": "ID is the **unique identifier** for this memory resource within the project.\nThis ID is used by agents to reference the memory in their configuration.\n- **Examples**: `\"user_conversation\"`, `\"session_context\"`, `\"agent_workspace\"`"
    },
    "description": {
      "type": "string",
      "description": "Description provides a **human-readable explanation** of the memory resource's purpose.\nThis helps developers understand what kind of data this memory stores and\nhow it should be used within workflows."
    },
    "version": {
      "type": "string",
      "description": "Version allows **tracking changes** to the memory resource definition.\nCan be used for migration strategies when memory schema evolves.\n**Format**: semantic versioning (e.g., `\"1.0.0\"`, `\"2.1.0-beta\"`)"
    },
    "type": {
      "type": "string",
      "description": "Type indicates the **primary memory management strategy**:\n- **`\"token_based\"`**: Manages memory based on token count limits (recommended for LLM contexts)\n- **`\"message_count_based\"`**: Manages memory based on message count limits\n- **`\"buffer\"`**: Simple buffer that stores messages up to a limit without sophisticated eviction"
    },
    "max_tokens": {
      "type": "integer",
      "description": "MaxTokens is the **hard limit** on the number of tokens this memory can hold.\nOnly applicable when Type is `\"token_based\"`. When this limit is reached,\nthe flushing strategy determines how to make room for new content.\n\n- **Example**: `4000` (roughly equivalent to ~3000 words)"
    },
    "max_messages": {
      "type": "integer",
      "description": "MaxMessages is the **hard limit** on the number of messages this memory can store.\nApplicable for `\"message_count_based\"` type or as a secondary limit for `\"token_based\"`.\n\n- **Example**: `100` (keeps last 100 messages in conversation)"
    },
    "max_context_ratio": {
      "type": "number",
      "description": "MaxContextRatio specifies the **maximum portion** of an LLM's context window this memory should use.\nValue between 0 and 1. Dynamically calculates MaxTokens based on the model's context window.\n\n- **Example**: `0.5` means use at most 50% of the model's context window for memory,\nleaving the rest for system prompts and current task context."
    },
    "token_allocation": {
      "$ref": "#/$defs/TokenAllocation",
      "description": "TokenAllocation defines how the **token budget is distributed** across different categories.\nOnly applicable for `token_based` memory type. All percentages **must sum to 1.0**.\n```yaml\ntoken_allocation:\n  short_term: 0.6  # 60% for recent messages\n  long_term: 0.3   # 30% for summarized context\n  system: 0.1      # 10% for system prompts\n```"
    },
    "flushing": {
      "$ref": "#/$defs/FlushingStrategyConfig",
      "description": "Flushing defines **how memory is managed** when limits are approached or reached.\n**Available strategies**:\n- **`\"simple_fifo\"`**: Removes oldest messages first (fastest, no LLM required)\n- **`\"lru\"`**: Removes least recently used messages (tracks access patterns)\n- **`\"hybrid_summary\"`**: Summarizes old messages before removal (requires LLM, preserves context)\n- **`\"token_aware_lru\"`**: LRU that considers token cost of messages (optimizes token usage)"
    },
    "persistence": {
      "$ref": "#/$defs/PersistenceConfig",
      "description": "Persistence defines **how memory instances are persisted** beyond process lifetime.\n**Required field** that specifies storage backend and retention policy.\n**Supported backends**:\n- **`\"redis\"`**: Production-grade persistence with distributed locking and TTL support\n- **`\"in_memory\"`**: Testing/development only, data lost on restart"
    },
    "privacy_policy": {
      "$ref": "#/$defs/PrivacyPolicyConfig",
      "description": "PrivacyPolicy defines **rules for handling sensitive data** within this memory.\nCan specify redaction patterns, non-persistable message types, and\ncustom redaction strings for **compliance with data protection regulations**.\n```yaml\nprivacy_policy:\n  redact_patterns: [\"\\\\b\\\\d{3}-\\\\d{2}-\\\\d{4}\\\\b\"]  # SSN pattern\n  non_persistable_message_types: [\"payment_info\"]\n  default_redaction_string: \"[REDACTED]\"\n```"
    },
    "locking": {
      "$ref": "#/$defs/LockConfig",
      "description": "Locking configures **distributed lock timeouts** for concurrent memory operations.\n**Critical for preventing race conditions** when multiple agents access the same memory.\nTimeouts can be configured per operation type:\n- **`append_ttl`**: Timeout for adding new messages (default: `30s`)\n- **`clear_ttl`**: Timeout for clearing memory (default: `10s`)\n- **`flush_ttl`**: Timeout for flush operations (default: `5m`)"
    },
    "token_provider": {
      "$ref": "#/$defs/TokenProviderConfig",
      "description": "TokenProvider configures **provider-specific token counting** for accurate limits.\nSupports OpenAI, Anthropic, and other providers with their specific tokenizers.\nCan specify API keys for **real-time token counting** or fallback strategies."
    }
  },
  "additionalProperties": false,
  "type": "object",
  "description": "Config defines the structure for a memory resource configuration.",
  "yamlCompatible": true
}