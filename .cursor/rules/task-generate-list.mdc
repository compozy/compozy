---
description: "Guide for creating detailed task lists from PRDs and tech specs, including complexity analysis and phased generation workflow"
alwaysApply: false
---
# Rule: Generating a Task List from a PRD

<goal>
To guide an AI assistant in creating a detailed, step-by-step task list in Markdown format based on an existing Product Requirements Document (PRD `.md`) and its corresponding Technical Specification document (tech spec `.md`). The task list should guide a developer through implementation following both functional requirements and architectural decisions.
</goal>

<output_specification>
- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-<prd-file-name>.md` (e.g., `tasks-prd-user-profile-editing.md`)
</output_specification>

## Process

<process_steps>
1.  **Receive PRD Reference:** The user points the AI to a specific PRD file
2.  **Verify Tech Spec:** Confirm that a corresponding tech spec document exists (`tasks/docs/prd-<feature>_techspec.md`). If not, remind the user to create it using [prd-tech-spec.mdc](mdc:.cursor/rules/prd-tech-spec.mdc) before proceeding with task generation.
3.  **Analyze PRD & Tech Spec:** The AI reads and analyzes both the functional requirements from the PRD and the implementation details from the tech spec document.
4.  **Phase 1: Generate Parent Tasks:** Based on the combined PRD and tech spec analysis, create the file and generate the main, high-level tasks required to implement the feature. Use your judgement on how many high-level tasks to use. It's likely to be about 5. Present these tasks to the user in the specified format (without sub-tasks yet). Inform the user: "I have generated the high-level tasks based on the PRD and tech spec. Ready to generate the sub-tasks? Respond with 'Go' to proceed."
5.  **Wait for Confirmation:** Pause and wait for the user to respond with "Go".
6.  **Phase 2: Generate Sub-Tasks:** Once the user confirms, break down each parent task into smaller, actionable sub-tasks necessary to complete the parent task. Ensure sub-tasks logically follow from the parent task and cover the implementation details from both the PRD and tech spec.
7.  **Phase 3: Analyze Task Complexity:** Use Zen MCP tools to analyze task complexity and identify tasks that need further breakdown. Generate a comprehensive complexity analysis report (typically saved as `task-complexity-report.json`) that includes complexity scores (1-10), recommended number of subtasks, reasoning for complexity assessment, and expansion prompts for each task. Tasks with complexity scores above the threshold (typically 6-7) should be broken down into more granular subtasks to ensure manageable implementation units.
8.  **Identify Relevant Files:** Based on the tasks, PRD, and tech spec, identify potential files that will need to be created or modified. List these under the `Relevant Files` section, including corresponding test files if applicable. Reference the tech spec's file structure and architectural decisions.
9.  **Generate Final Output:** Combine the parent tasks, sub-tasks, relevant files, and notes into the final Markdown structure.
10. **Save Task List:** Save the generated document in the `/tasks/` directory with the filename `tasks-<prd-file-name>.md`, where `<prd-file-name>` matches the base name of the input PRD file (e.g., if the input was `prd-user-profile-editing.md`, the output is `tasks-prd-user-profile-editing.md`).
</process_steps>

<complexity_analysis_features>
**The complexity report includes:**
- Metadata: generation timestamp, tasks analyzed count, threshold score, project name
- Per-task analysis: complexity scores with detailed reasoning
- Recommended subtask counts based on complexity assessment
- Specific expansion prompts for breaking down complex tasks
- Threshold-based recommendations for further subdivision
</complexity_analysis_features>

## Output Format

<output_format_template>
The generated task list _must_ follow this structure:

```markdown
## Relevant Files

- `path/to/potential/file1.ts` - Brief description of why this file is relevant (e.g., Contains the main component for this feature).
- `path/to/file1.test.ts` - Unit tests for `file1.ts`.
- `path/to/another/file.tsx` - Brief description (e.g., API route handler for data submission).
- `path/to/another/file.test.tsx` - Unit tests for `another/file.tsx`.
- `lib/utils/helpers.ts` - Brief description (e.g., Utility functions needed for calculations).
- `lib/utils/helpers.test.ts` - Unit tests for `helpers.ts`.

### Notes

- Unit tests should typically be placed alongside the code files they are testing (e.g., `MyComponent.tsx` and `MyComponent.test.tsx` in the same directory).
- Use `npx jest [optional/path/to/test/file]` to run tests. Running without a path executes all tests found by the Jest configuration.

## Tasks

- [ ] 1.0 Parent Task Title
  - [ ] 1.1 [Sub-task description 1.1]
  - [ ] 1.2 [Sub-task description 1.2]
- [ ] 2.0 Parent Task Title
  - [ ] 2.1 [Sub-task description 2.1]
- [ ] 3.0 Parent Task Title (may not require sub-tasks if purely structural or configuration)
```
</output_format_template>

## Interaction Model

<interaction_model>
The process explicitly requires a pause after generating parent tasks to get user confirmation ("Go") before proceeding to generate the detailed sub-tasks. This ensures the high-level plan aligns with user expectations before diving into details.
</interaction_model>

<target_audience>
Assume the primary reader of the task list is a **junior developer** who will implement the feature.
</target_audience>
